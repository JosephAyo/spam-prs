{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4babdda8-11f7-485e-bad8-d8c5b8eebb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import datetime\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Read tokens from a text file\n",
    "tokens_file = \"./env/tokens.txt\"\n",
    "with open(tokens_file, \"r\") as file:\n",
    "    tokens = file.read().splitlines()\n",
    "\n",
    "# Create an iterator to cycle through the tokens\n",
    "token_iterator = itertools.cycle(tokens)\n",
    "current_token = next(token_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c281d1-993b-497b-8984-0e32ac6a61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of User-Agents for randomization\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "]\n",
    "\n",
    "# Define headers to authenticate using the first token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {current_token}\",\n",
    "    \"User-Agent\": random.choice(user_agents),\n",
    "}\n",
    "\n",
    "# Setup GraphQL endpoint and client\n",
    "graphql_url = \"https://api.github.com/graphql\"\n",
    "transport = RequestsHTTPTransport(url=graphql_url, headers=headers, use_json=True)\n",
    "client = Client(transport=transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d7c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_activity(activity: str):\n",
    "    log = f\"{datetime.datetime.now()}: {activity}\\n\"\n",
    "    # print(log)\n",
    "    with open(\"spam-prs-output.log\", \"a\") as log_file:\n",
    "        log_file.write(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5062f1b0-a9df-4f94-bb18-56f42774bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all tokens to verify their validity\n",
    "def test_all_tokens():\n",
    "    test_query = gql(\n",
    "        \"\"\"\n",
    "        {\n",
    "          viewer {\n",
    "            login\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "    )\n",
    "    for i, token in enumerate(tokens):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"User-Agent\": random.choice(user_agents),\n",
    "        }\n",
    "        transport = RequestsHTTPTransport(\n",
    "            url=graphql_url, headers=headers, use_json=True\n",
    "        )\n",
    "        client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "\n",
    "        try:\n",
    "            response = client.execute(test_query)\n",
    "            log_activity(\n",
    "                f\"Token {i+1}/{len(tokens)} is valid. Logged in as: {response['viewer']['login']}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            log_activity(f\"Token {i+1}/{len(tokens)} failed with error: {e}\")\n",
    "\n",
    "\n",
    "# Run the token validation\n",
    "test_all_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd85df0-71b7-46c8-9ed4-eceb724201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphQL query\n",
    "query_template = gql(\n",
    "    \"\"\"\n",
    "    query searchIssues($keyword: String!, $afterCursor: String, $first: Int) {\n",
    "      search(query: $keyword, type: ISSUE, first: $first, after: $afterCursor) {\n",
    "        issueCount\n",
    "        edges {\n",
    "          cursor\n",
    "          node {\n",
    "            ... on PullRequest {\n",
    "              id\n",
    "              number\n",
    "              title\n",
    "              url\n",
    "              comments(first: 100) {\n",
    "                totalCount # it still gives the total count regardless of the first parameter\n",
    "                edges {\n",
    "                  node {   \n",
    "                    author { ... on User { login } }\n",
    "                    editor { ... on User { login } }\n",
    "                    body\n",
    "                    createdAt\n",
    "                    lastEditedAt\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              state\n",
    "              closed\n",
    "              merged\n",
    "              createdAt\n",
    "              updatedAt\n",
    "              mergeCommit {\n",
    "                oid\n",
    "              }\n",
    "              timeline(last: 100) {\n",
    "                edges {\n",
    "                  node {\n",
    "                    __typename\n",
    "                    ... on LabeledEvent {\n",
    "                      actor { ... on User { login } }\n",
    "                      label { ... on Label { name }}\n",
    "                      createdAt\n",
    "                    }\n",
    "                    ... on ClosedEvent { \n",
    "                      actor { ... on User { login } }\n",
    "                      createdAt\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              commits(first: 100) {\n",
    "                totalCount\n",
    "                pageInfo {\n",
    "                  hasNextPage\n",
    "                  endCursor\n",
    "                }\n",
    "                edges {\n",
    "                  node {\n",
    "                    commit {\n",
    "                      oid\n",
    "                      message\n",
    "                      author { ... on GitActor { name } }\n",
    "                      changedFilesIfAvailable\n",
    "                      commitUrl\n",
    "                      committedDate\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              changedFiles\n",
    "              headRefName\n",
    "              baseRefName\n",
    "              repository {\n",
    "                id\n",
    "                nameWithOwner\n",
    "                stargazerCount\n",
    "                description\n",
    "                codeOfConduct {\n",
    "                  body\n",
    "                  id\n",
    "                  name\n",
    "                  url\n",
    "                }\n",
    "                homepageUrl\n",
    "                assignableUsers(first: 100) {\n",
    "                  edges {\n",
    "                    node {\n",
    "                      login\n",
    "                      url\n",
    "                      bio\n",
    "                      company\n",
    "                    }\n",
    "                  }\n",
    "                  totalCount\n",
    "                }\n",
    "                mentionableUsers(first: 100) {\n",
    "                  edges {\n",
    "                    node {\n",
    "                      login\n",
    "                      url\n",
    "                      bio\n",
    "                      company\n",
    "                    }\n",
    "                  }\n",
    "                  totalCount\n",
    "                }\n",
    "                forkCount\n",
    "                watchers {\n",
    "                  totalCount\n",
    "                }\n",
    "                isFork\n",
    "                languages(first: 20) {\n",
    "                  edges {\n",
    "                    node {\n",
    "                      name\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              author {\n",
    "                ... on User {\n",
    "                  login\n",
    "                  url\n",
    "                  createdAt\n",
    "                  repositories {\n",
    "                    totalCount\n",
    "                  }\n",
    "                  followers {\n",
    "                    totalCount\n",
    "                  }\n",
    "                  following {\n",
    "                    totalCount\n",
    "                  }\n",
    "                  repositoryDiscussions {\n",
    "                    totalCount\n",
    "                  }\n",
    "                  repositoryDiscussionComments {\n",
    "                    totalCount\n",
    "                  }\n",
    "                  organizations (first: 20){\n",
    "                    edges {\n",
    "                      node {\n",
    "                        name\n",
    "                        login\n",
    "                        url\n",
    "                        membersWithRole {\n",
    "                          totalCount\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              labels(first: 10) {\n",
    "                edges {\n",
    "                  node {\n",
    "                    name\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              body\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        pageInfo {\n",
    "          endCursor\n",
    "          hasNextPage\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b32e41-7d3f-458b-ad0f-0c13d3146813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_contributor_count(repo_owner, repo_name):\n",
    "#     global current_token\n",
    "#     max_retries = 3\n",
    "#     retries = 0\n",
    "#     while retries < max_retries:\n",
    "#         try:\n",
    "#             # Randomize User-Agent for each query\n",
    "#             headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "#             headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "#             url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contributors?per_page=1&anon=true\"\n",
    "#             response = requests.get(url, headers=headers)\n",
    "#             if response.status_code == 200:\n",
    "#                 return int(response.headers.get(\"Link\", \"\").split(\",\")[-1].split(\"&page=\")[-1].split(\">\")[0]) if \"Link\" in response.headers else len(response.json())\n",
    "#             elif response.status_code == 403:\n",
    "#                 print(f\"Rate limit exceeded, switching token... (Attempt {retries + 1}/{max_retries})\")\n",
    "#                 current_token = next(token_iterator)\n",
    "#                 retries += 1\n",
    "#             else:\n",
    "#                 response.raise_for_status()\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error: {e}, retrying... (Attempt {retries + 1}/{max_retries})\")\n",
    "#             retries += 1\n",
    "#     raise Exception(\"Max retries reached. Unable to complete the request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac2c2427-7797-4088-a144-6045c87ee349",
   "metadata": {},
   "outputs": [],
   "source": [
    "transport.headers = headers\n",
    "# Check rate limit before executing the main query\n",
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "rate_limit_response = client.execute(rate_limit_query)\n",
    "log_activity(f\"Rate limit: {rate_limit_response['rateLimit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49acb9fd-7a25-458d-aec7-8f302a653c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def execute_query(keyword, first=100, after_cursor=None):\n",
    "    global current_token\n",
    "    log_activity(\n",
    "        f\"Executing query with keyword: {keyword}, first: {first}, afterCursor: {after_cursor}\"\n",
    "    )\n",
    "    while True:\n",
    "        try:\n",
    "            # Randomize User-Agent for each query\n",
    "            headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "            transport.headers = headers\n",
    "            # Check rate limit before executing the main query\n",
    "            rate_limit_response = client.execute(rate_limit_query)\n",
    "            remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "            if remaining < 100:\n",
    "                log_activity(\n",
    "                    f\"Rate limit remaining ({remaining}) is below threshold. Switching token...\"\n",
    "                )\n",
    "                # Set up to track whether we have cycled through all tokens\n",
    "                all_tokens_checked = False\n",
    "                initial_token = current_token\n",
    "\n",
    "                while not all_tokens_checked:\n",
    "                    # Switch to the next token\n",
    "                    current_token = next(token_iterator)\n",
    "                    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "                    transport.headers = headers\n",
    "\n",
    "                    # Check the rate limit of the new token\n",
    "                    rate_limit_response = client.execute(rate_limit_query)\n",
    "                    remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "\n",
    "                    if remaining >= 100:\n",
    "                        log_activity(\n",
    "                            f\"Switched to a new token with sufficient rate limit ({remaining} remaining).\"\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    # Check if we have cycled through all tokens\n",
    "                    if current_token == initial_token:\n",
    "                        log_activity(\"All tokens are below threshold. Waiting for 1 hour...\")\n",
    "                        time.sleep(3600)\n",
    "                        all_tokens_checked = True\n",
    "\n",
    "                continue\n",
    "            return client.execute(\n",
    "                query_template,\n",
    "                variable_values={\n",
    "                    \"keyword\": keyword,\n",
    "                    \"first\": first,\n",
    "                    \"afterCursor\": after_cursor,\n",
    "                },\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if \"API rate limit\" in str(e):\n",
    "                log_activity(\n",
    "                    f\"Rate limit reached: {e}, switching token... (Attempt with first {first})\"\n",
    "                )\n",
    "                current_token = next(token_iterator)\n",
    "                headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "            else:\n",
    "                if first > 1:\n",
    "                    first = max(1, first // 2)\n",
    "                    log_activity(\n",
    "                        f\"Error: {e}, reducing number of results and retrying... (Attempt with first {first})\"\n",
    "                    )\n",
    "                else:\n",
    "                    break\n",
    "    log_activity(\"Max retries reached. Sleeping for 10 minutes and switching token...\")\n",
    "    time.sleep(600)\n",
    "    current_token = next(token_iterator)\n",
    "    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "    transport.headers = headers\n",
    "    return execute_query(keyword, first, after_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e2f9a0-95df-4b00-8544-efeb1ba4d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if os.path.exists(\"progress.pkl\"):\n",
    "    with open(\"progress.pkl\", \"rb\") as f:\n",
    "        progress_data = pickle.load(f)\n",
    "        df = progress_data[\"df\"]\n",
    "        start_index = progress_data[\"start_index\"]\n",
    "else:\n",
    "    df = []\n",
    "    start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69df882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb89147-ab2c-4654-a8d7-637737c90537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m after_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_keyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter_cursor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mafter_cursor\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     log_activity(\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missueCount\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missueCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missueCount\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mexecute_query\u001b[0;34m(keyword, first, after_cursor)\u001b[0m\n\u001b[1;32m     27\u001b[0m transport\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;241m=\u001b[39m headers\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Check rate limit before executing the main query\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m rate_limit_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate_limit_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m remaining \u001b[38;5;241m=\u001b[39m rate_limit_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrateLimit\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremaining\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/gql/client.py:484\u001b[0m, in \u001b[0;36mClient.execute\u001b[0;34m(self, document, variable_values, operation_name, serialize_variables, parse_result, get_execution_result, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Sync transports\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserialize_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialize_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_execution_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_execution_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/gql/client.py:248\u001b[0m, in \u001b[0;36mClient.execute_sync\u001b[0;34m(self, document, variable_values, operation_name, serialize_variables, parse_result, get_execution_result, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\":meta private:\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserialize_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialize_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_execution_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_execution_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/gql/client.py:1017\u001b[0m, in \u001b[0;36mSyncClientSession.execute\u001b[0;34m(self, document, variable_values, operation_name, serialize_variables, parse_result, get_execution_result, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the provided document AST synchronously using\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03mthe sync transport.\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m \u001b[38;5;124;03mThe extra arguments are passed to the transport execute method.\"\"\"\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# Validate and execute on the transport\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialize_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialize_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# Raise an error if an error is returned in the ExecutionResult object\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/gql/client.py:926\u001b[0m, in \u001b[0;36mSyncClientSession._execute\u001b[0;34m(self, document, variable_values, operation_name, serialize_variables, parse_result, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m     result \u001b[38;5;241m=\u001b[39m future_result\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# Unserialize the result if requested\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mschema:\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/gql/transport/requests.py:237\u001b[0m, in \u001b[0;36mRequestsHTTPTransport.execute\u001b[0;34m(self, document, variable_values, operation_name, timeout, extra_args, upload_files)\u001b[0m\n\u001b[1;32m    234\u001b[0m     post_args\u001b[38;5;241m.\u001b[39mupdate(extra_args)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Using the created session to perform requests\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpost_args\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_headers \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_response_error\u001b[39m(resp: requests\u001b[38;5;241m.\u001b[39mResponse, reason: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# We raise a TransportServerError if the status code is 400 or higher\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# We raise a TransportProtocolError in the other cases\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Documents/ayo-workspace/iwadi/spam/spam/lib/python3.13/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1430\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os import close\n",
    "\n",
    "# template\n",
    "keywords = ['\"ai spam\"', \"spam\", \"ai-spam\"]\n",
    "index = start_index\n",
    "se_fm_repository_data = df\n",
    "current_date = datetime.datetime.now()\n",
    "github_earliest_datetime = datetime.datetime(2019, 1, 1)\n",
    "start_date = github_earliest_datetime\n",
    "end_date = current_date\n",
    "max_total_allowed_results = 150\n",
    "default_days_interval = 60\n",
    "days_interval = default_days_interval\n",
    "\n",
    "while start_date < end_date:\n",
    "    start_date = next_date\n",
    "    next_date = start_date + datetime.timedelta(days=days_interval)\n",
    "    date_range = f\"{start_date.strftime('%Y-%m-%d')}..{next_date.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "    for keyword in tqdm(keywords):\n",
    "        search_keyword = (\n",
    "            f\"label:{keyword} is:pr is:public archived:false created:{date_range}\"\n",
    "        )\n",
    "        try:\n",
    "            after_cursor = None\n",
    "            while True:\n",
    "                response = execute_query(\n",
    "                    search_keyword, first=10, after_cursor=after_cursor\n",
    "                )\n",
    "                log_activity(\n",
    "                    f'response[\"search\"][\"issueCount\"]: {response[\"search\"][\"issueCount\"]}\\n'\n",
    "                )\n",
    "                if response[\"search\"][\"issueCount\"] == 0:\n",
    "                    break\n",
    "                # Adjust interval based on issue count\n",
    "                if response[\"search\"][\"issueCount\"] > max_total_allowed_results:\n",
    "                    reduced_interval = max(1, days_interval // 2)\n",
    "                    log_activity(\n",
    "                        f\"count exceeds: {max_total_allowed_results}, reducing interval to {reduced_interval} days...\\n\"\n",
    "                    )\n",
    "                    days_interval = reduced_interval  # Reduce interval to half\n",
    "                    next_date = start_date + datetime.timedelta(days=days_interval)\n",
    "                    date_range: str = f\"{start_date.strftime('%Y-%m-%d')}..{next_date.strftime('%Y-%m-%d')}\"\n",
    "                    break\n",
    "                else:\n",
    "                    days_interval = default_days_interval  # Reset interval to normal\n",
    "                    next_date = start_date + datetime.timedelta(days=days_interval)\n",
    "\n",
    "                # Extract pr\n",
    "                for edge in response[\"search\"][\"edges\"]:\n",
    "                    pull_request = edge[\"node\"]\n",
    "\n",
    "                    if not pull_request:\n",
    "                        continue\n",
    "                    timeline = pull_request[\"timeline\"][\"edges\"]\n",
    "                    labeled_spam_event = next(\n",
    "                        filter(\n",
    "                            lambda x: x[\"node\"]\n",
    "                            and x[\"node\"][\"__typename\"] == \"LabeledEvent\"\n",
    "                            and x[\"node\"][\"label\"][\"name\"]\n",
    "                            and (x[\"node\"][\"label\"][\"name\"]).lower()\n",
    "                            == keyword.strip('\"').lower(),\n",
    "                            timeline,\n",
    "                        ),\n",
    "                        None,\n",
    "                    )\n",
    "\n",
    "                    labeled_spam_event_node = (\n",
    "                        labeled_spam_event[\"node\"] if labeled_spam_event else None\n",
    "                    )\n",
    "                    closed_event = next(\n",
    "                        filter(\n",
    "                            lambda x: x[\"node\"]\n",
    "                            and x[\"node\"][\"__typename\"] == \"ClosedEvent\",\n",
    "                            timeline,\n",
    "                        ),\n",
    "                        None,\n",
    "                    )\n",
    "                    closed_event_node = closed_event[\"node\"] if closed_event else None\n",
    "                    author = pull_request[\"author\"]\n",
    "                    comments = [\n",
    "                        comment[\"node\"] for comment in pull_request[\"comments\"][\"edges\"]\n",
    "                    ]\n",
    "                    labeled_spam_at = (\n",
    "                        labeled_spam_event_node[\"createdAt\"]\n",
    "                        if labeled_spam_event_node\n",
    "                        else None\n",
    "                    )\n",
    "\n",
    "                    labeled_spam_by = (\n",
    "                        labeled_spam_event_node[\"actor\"][\"login\"]\n",
    "                        if labeled_spam_event_node and labeled_spam_event_node[\"actor\"]\n",
    "                        else None\n",
    "                    )\n",
    "                    comments_by_spam_labeler = [\n",
    "                        {\n",
    "                            **labeler_comment,\n",
    "                            \"commented_before_labeling_spam\": (\n",
    "                                labeler_comment[\"createdAt\"] < labeled_spam_at\n",
    "                                if (labeler_comment[\"createdAt\"] and labeled_spam_at)\n",
    "                                is not None\n",
    "                                else None\n",
    "                            ),\n",
    "                        }\n",
    "                        for labeler_comment in comments\n",
    "                        if (\n",
    "                            (\n",
    "                                labeler_comment[\"author\"]\n",
    "                                and labeler_comment[\"author\"][\"login\"]\n",
    "                                == labeled_spam_by\n",
    "                            )\n",
    "                            or (not labeler_comment[\"author\"] and not labeled_spam_by)\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                    closed_by = (\n",
    "                        closed_event_node[\"actor\"][\"login\"]\n",
    "                        if closed_event_node and closed_event_node[\"actor\"]\n",
    "                        else None\n",
    "                    )\n",
    "                    closed_at = (\n",
    "                        closed_event_node[\"createdAt\"] if closed_event_node else None\n",
    "                    )\n",
    "                    comments_by_closer = [\n",
    "                        {\n",
    "                            **closer_comment,\n",
    "                            \"commented_before_closing\": (\n",
    "                                closer_comment[\"createdAt\"] < closed_at\n",
    "                                if closed_at\n",
    "                                else False\n",
    "                            ),\n",
    "                        }\n",
    "                        for closer_comment in comments\n",
    "                        if (\n",
    "                            (\n",
    "                                closer_comment[\"author\"]\n",
    "                                and closer_comment[\"author\"][\"login\"] == closed_by\n",
    "                            )\n",
    "                            or (not closer_comment[\"author\"] and not closed_by)\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                    author_organizations = (\n",
    "                        [\n",
    "                            organization[\"node\"]\n",
    "                            for organization in author[\"organizations\"][\"edges\"]\n",
    "                            if organization[\"node\"]\n",
    "                        ]\n",
    "                        if author\n",
    "                        and author.get(\"organizations\")\n",
    "                        and author[\"organizations\"].get(\"edges\")\n",
    "                        else []\n",
    "                    )\n",
    "\n",
    "                    timestamp_suffix = (\n",
    "                        f\"_as_at_{datetime.datetime.now().strftime('%Y-%m-%d')}\"\n",
    "                    )\n",
    "\n",
    "                    df.append(\n",
    "                        {\n",
    "                            \"id\": pull_request[\"id\"],\n",
    "                            \"title\": pull_request[\"title\"],\n",
    "                            \"url\": pull_request[\"url\"],\n",
    "                            \"state\": pull_request[\"state\"],\n",
    "                            \"comments_count\": pull_request[\"comments\"][\"totalCount\"],\n",
    "                            \"comments_by_spam_labeler_count\": len(\n",
    "                                comments_by_spam_labeler\n",
    "                            ),\n",
    "                            \"comments_by_spam_labeler\": comments_by_spam_labeler,\n",
    "                            \"labeled_spam_by\": (\n",
    "                                labeled_spam_event_node[\"actor\"][\"login\"]\n",
    "                                if labeled_spam_event_node\n",
    "                                and labeled_spam_event_node[\"actor\"]\n",
    "                                else None\n",
    "                            ),\n",
    "                            \"is_labeled_spam_by_bot\": labeled_spam_by is None,\n",
    "                            \"labeled_spam_at\": labeled_spam_at,\n",
    "                            \"comments_by_closer_count\": len(comments_by_closer),\n",
    "                            \"comments_by_closer\": comments_by_closer,\n",
    "                            \"closed\": pull_request[\"closed\"],\n",
    "                            \"is_closed_by_bot\": closed_by is None,\n",
    "                            \"closed_by\": closed_by,\n",
    "                            \"closed_at\": closed_at,\n",
    "                            \"merged\": pull_request[\"merged\"],\n",
    "                            \"body\": pull_request[\"body\"],\n",
    "                            \"created_at\": pull_request[\"createdAt\"],\n",
    "                            \"updated_at\": pull_request[\"updatedAt\"],\n",
    "                            \"repository\": pull_request[\"repository\"],\n",
    "                            \"repository_name_with_owner\": pull_request[\"repository\"][\n",
    "                                \"nameWithOwner\"\n",
    "                            ],\n",
    "                            \"repository_stargazer_count\": pull_request[\"repository\"][\n",
    "                                \"stargazerCount\"\n",
    "                            ],\n",
    "                            \"repository_watcher_count\": pull_request[\"repository\"][\n",
    "                                \"watchers\"\n",
    "                            ][\"totalCount\"],\n",
    "                            \"repository_is_fork\": pull_request[\"repository\"][\"isFork\"],\n",
    "                            \"repository_languages\": [\n",
    "                                language[\"node\"][\"name\"]\n",
    "                                for language in pull_request[\"repository\"][\"languages\"][\n",
    "                                    \"edges\"\n",
    "                                ]\n",
    "                            ],\n",
    "                            \"merge_commit\": (\n",
    "                                pull_request[\"mergeCommit\"][\"oid\"]\n",
    "                                if pull_request[\"mergeCommit\"]\n",
    "                                else None\n",
    "                            ),\n",
    "                            \"labels\": [\n",
    "                                label[\"node\"][\"name\"]\n",
    "                                for label in pull_request[\"labels\"][\"edges\"]\n",
    "                            ],\n",
    "                            \"commits_count\": pull_request[\"commits\"][\"totalCount\"],\n",
    "                            \"changed_files_count\": pull_request[\"changedFiles\"],\n",
    "                            \"commits\": pull_request[\"commits\"][\"edges\"],\n",
    "                            \"author_name\": (author[\"login\"] if author else None),\n",
    "                            \"author_url\": (author[\"url\"] if author else None),\n",
    "                            \"author_account_created_at\": (\n",
    "                                author[\"createdAt\"] if author else None\n",
    "                            ),\n",
    "                            f\"author_repository_count{timestamp_suffix}\": (\n",
    "                                author[\"repositories\"][\"totalCount\"]\n",
    "                                if author and author[\"repositories\"]\n",
    "                                else None\n",
    "                            ),\n",
    "                            f\"author_followers_count{timestamp_suffix}\": (\n",
    "                                author[\"followers\"][\"totalCount\"]\n",
    "                                if author and author[\"followers\"]\n",
    "                                else None\n",
    "                            ),\n",
    "                            f\"author_following_count{timestamp_suffix}\": (\n",
    "                                author[\"following\"][\"totalCount\"]\n",
    "                                if author and author[\"following\"]\n",
    "                                else None\n",
    "                            ),\n",
    "                            f\"author_repository_discussions_count{timestamp_suffix}\": (\n",
    "                                author[\"repositoryDiscussions\"][\"totalCount\"]\n",
    "                                if author and author[\"repositoryDiscussions\"]\n",
    "                                else None\n",
    "                            ),\n",
    "                            f\"author_repository_discussion_comments_count{timestamp_suffix}\": (\n",
    "                                author[\"repositoryDiscussionComments\"][\"totalCount\"]\n",
    "                                if author and author[\"repositoryDiscussionComments\"]\n",
    "                                else None\n",
    "                            ),\n",
    "                            f\"author_organizations{timestamp_suffix}\": author_organizations,\n",
    "                            \"spam_search_keyword\": keyword,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                # Pagination\n",
    "                page_info = response[\"search\"][\"pageInfo\"]\n",
    "                if page_info[\"hasNextPage\"]:\n",
    "                    after_cursor = page_info[\"endCursor\"]\n",
    "                else:\n",
    "                    break\n",
    "            with open(\"progress.pkl\", \"wb\") as f:\n",
    "                pickle.dump({\"df\": se_fm_repository_data, \"start_index\": index + 1}, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            log_activity(\n",
    "                f\"Failed to retrieve data for keywords '{keyword}' in date range: {date_range} {e}\"\n",
    "            )\n",
    "            # Save progress before terminating\n",
    "            with open(\"progress.pkl\", \"wb\") as f:\n",
    "                pickle.dump({\"df\": df, \"start_index\": index}, f)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_pkl_content(filepath):\n",
    "    \"\"\"\n",
    "    Display the content of a pickle file and save it as CSV and JSON files.\n",
    "\n",
    "    This function reads a pickle file from the given filepath, prints its content,\n",
    "    and saves the data contained in the \"df\" key to both a CSV file and a JSON file.\n",
    "    The CSV file is saved with the name \"spam_data_without_org_join_date.csv\" and the JSON file is saved\n",
    "    with the name \"spam_data_without_org_join_date.json\".\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the pickle file to be read.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If there is an error reading the pickle file or writing the CSV/JSON files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        log_activity(f\"Content of {filepath}:\\n\")\n",
    "        filename = \"spam_data_without_org_join_date\"\n",
    "        pd.DataFrame(data[\"df\"]).to_csv(f\"{filename}.csv\", index=True)\n",
    "        log_activity(f\"Data written to {filename}.csv successfully.\")\n",
    "        try:\n",
    "            with open(f\"{filename}.json\", \"w\") as f:\n",
    "                json.dump(data[\"df\"], f, indent=4)\n",
    "            log_activity(f\"Data written to {filename}.json successfully.\")\n",
    "        except Exception as e:\n",
    "            log_activity(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        log_activity(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "filepath = \"progress.pkl\"\n",
    "display_pkl_content(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0deeda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate metadata\n",
    "df = []\n",
    "start_index = 0\n",
    "\n",
    "\n",
    "\n",
    "def generate_metadata(filepath):\n",
    "    \"\"\" \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        print(f\"Content of {filepath}:\\n\")\n",
    "        filename = \"spam_data.meta\"\n",
    "        pull_requests = data[\"df\"]\n",
    "        unique_repository = {}\n",
    "        unique_pr_author = {}\n",
    "        unique_pr_spam_labeler = {}\n",
    "        unique_pr_closer = {}\n",
    "        merged_pr_count = 0\n",
    "        closed_pr_count = 0\n",
    "        for pull_request in pull_requests:\n",
    "            def update_unique_value_dict(info_dict, key, value):\n",
    "                if not value:\n",
    "                    print(f\"Warning: Pull request missing '{key}' {pull_request}\")\n",
    "                    return False\n",
    "                if value not in info_dict:\n",
    "                    info_dict[value] = value\n",
    "                return True\n",
    "\n",
    "            # Update repository count\n",
    "            update_unique_value_dict(unique_repository, \"repository_name_with_owner\", pull_request[\"repository_name_with_owner\"])\n",
    "\n",
    "            # Update author count\n",
    "            update_unique_value_dict(unique_pr_author, \"author_name\", pull_request[\"author_name\"])\n",
    "\n",
    "            # Update spam labeler count\n",
    "            update_unique_value_dict(unique_pr_spam_labeler, \"labeled_spam_by\", pull_request[\"labeled_spam_by\"])\n",
    "\n",
    "            # Update closer count\n",
    "            update_unique_value_dict(unique_pr_closer, \"closed_by\", pull_request[\"closed_by\"])\n",
    "\n",
    "            merged_pr_count += 1 if pull_request[\"merged\"] else 0\n",
    "            closed_pr_count += 1 if pull_request[\"closed\"] is not None else 0\n",
    "\n",
    "\n",
    "        total_prs= len(pull_requests)\n",
    "        unique_repository_count= len(unique_repository)\n",
    "        unique_pr_author_count= len(unique_pr_author)\n",
    "        unique_pr_spam_labeler_count= len(unique_pr_spam_labeler)\n",
    "        unique_pr_closer_count= len(unique_pr_closer)\n",
    "        \n",
    "        df.append(\n",
    "            {\n",
    "            \"total_prs\": total_prs,\n",
    "            \"unique_repository_count\": unique_repository_count,\n",
    "            \"unique_repository_ratio\": round(unique_repository_count / total_prs, 3),\n",
    "            \"unique_pr_author_count\": unique_pr_author_count,\n",
    "            \"unique_pr_author_ratio\": round(unique_pr_author_count / total_prs, 3),\n",
    "            \"unique_pr_spam_labeler_count\": unique_pr_spam_labeler_count,\n",
    "            \"unique_pr_spam_labeler_ratio\": round(unique_pr_spam_labeler_count / total_prs, 3),\n",
    "            \"unique_pr_closer_count\": unique_pr_closer_count,\n",
    "            \"unique_pr_closer_ratio\": round(unique_pr_closer_count / total_prs, 3),\n",
    "            \"merged_pr_count\": merged_pr_count,\n",
    "            \"merged_pr_ratio\": round(merged_pr_count / total_prs, 3),\n",
    "            \"closed_pr_count\": closed_pr_count,\n",
    "            \"closed_pr_ratio\": round(closed_pr_count / total_prs, 3),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        pd.DataFrame(df).to_csv(f\"{filename}.csv\", index=True)\n",
    "        log_activity(f\"Data written to {filename}.csv successfully.\")\n",
    "        try:\n",
    "            with open(f\"{filename}.json\", \"w\") as f:\n",
    "                json.dump(df, f, indent=4)\n",
    "            log_activity(f\"Data written to {filename}.json successfully.\")\n",
    "        except Exception as e:\n",
    "            log_activity(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        log_activity(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "filepath = \"progress.pkl\"\n",
    "generate_metadata(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469812ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
