{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4babdda8-11f7-485e-bad8-d8c5b8eebb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "from datetime import datetime\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Read tokens from a text file\n",
    "tokens_file = \"./env/tokens.txt\"\n",
    "with open(tokens_file, \"r\") as file:\n",
    "    tokens = file.read().splitlines()\n",
    "\n",
    "# Create an iterator to cycle through the tokens\n",
    "token_iterator = itertools.cycle(tokens)\n",
    "current_token = next(token_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c281d1-993b-497b-8984-0e32ac6a61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of User-Agents for randomization\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "]\n",
    "\n",
    "# Define headers to authenticate using the first token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {current_token}\",\n",
    "    \"User-Agent\": random.choice(user_agents),\n",
    "}\n",
    "\n",
    "# Setup GraphQL endpoint and client\n",
    "graphql_url = \"https://api.github.com/graphql\"\n",
    "transport = RequestsHTTPTransport(url=graphql_url, headers=headers, use_json=True)\n",
    "client = Client(transport=transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062f1b0-a9df-4f94-bb18-56f42774bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all tokens to verify their validity\n",
    "def test_all_tokens():\n",
    "    test_query = gql(\n",
    "        \"\"\"\n",
    "        {\n",
    "          viewer {\n",
    "            login\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "    )\n",
    "    for i, token in enumerate(tokens):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"User-Agent\": random.choice(user_agents),\n",
    "        }\n",
    "        transport = RequestsHTTPTransport(\n",
    "            url=graphql_url, headers=headers, use_json=True\n",
    "        )\n",
    "        client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "\n",
    "        try:\n",
    "            response = client.execute(test_query)\n",
    "            print(\n",
    "                f\"Token {i+1}/{len(tokens)} is valid. Logged in as: {response['viewer']['login']}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Token {i+1}/{len(tokens)} failed with error: {e}\")\n",
    "\n",
    "\n",
    "# Run the token validation\n",
    "test_all_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdd85df0-71b7-46c8-9ed4-eceb724201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphQL query\n",
    "query_template = gql(\n",
    "    \"\"\"\n",
    "    query searchIssues($keyword: String!, $afterCursor: String, $first: Int) {\n",
    "      search(query: $keyword, type: ISSUE, first: $first, after: $afterCursor) {\n",
    "        issueCount\n",
    "        edges {\n",
    "          cursor\n",
    "          node {\n",
    "            ... on PullRequest {\n",
    "              id\n",
    "              number\n",
    "              title\n",
    "              url\n",
    "              comments(first: 100) {\n",
    "                totalCount # it still gives the total count regardless of the first parameter\n",
    "                edges {\n",
    "                  node {   \n",
    "                    author { ... on User { login } }\n",
    "                    editor { ... on User { login } }\n",
    "                    body\n",
    "                    createdAt\n",
    "                    lastEditedAt\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              state\n",
    "              merged\n",
    "              createdAt\n",
    "              updatedAt\n",
    "              mergeCommit {\n",
    "                oid\n",
    "              }\n",
    "              timeline(last: 100) {\n",
    "                edges {\n",
    "                  node {\n",
    "                    __typename\n",
    "                    ... on LabeledEvent {\n",
    "                      actor { ... on User { login } }\n",
    "                      label { ... on Label { name }}\n",
    "                      createdAt\n",
    "                    }\n",
    "                    ... on ClosedEvent { \n",
    "                      actor { ... on User { login } }\n",
    "                      createdAt\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              commits(first: 100) {\n",
    "                totalCount\n",
    "                pageInfo {\n",
    "                  hasNextPage\n",
    "                  endCursor\n",
    "                }\n",
    "                edges {\n",
    "                  node {\n",
    "                    commit {\n",
    "                      oid\n",
    "                      message\n",
    "                      author { ... on GitActor { name } }\n",
    "                      changedFilesIfAvailable\n",
    "                      commitUrl\n",
    "                      committedDate\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              changedFiles\n",
    "              headRefName\n",
    "              baseRefName\n",
    "              repository {\n",
    "                nameWithOwner\n",
    "                stargazerCount\n",
    "                isFork\n",
    "              }\n",
    "              author {\n",
    "                ... on User {\n",
    "                  login\n",
    "                  url\n",
    "                  repositories {\n",
    "                    totalCount\n",
    "                  }\n",
    "                  contributionsCollection { # it is limited to one year\n",
    "                    contributionCalendar {\n",
    "                      totalContributions\n",
    "                    }\n",
    "                  }\n",
    "                  followers {\n",
    "                    totalCount\n",
    "                  }\n",
    "                  following {\n",
    "                    totalCount\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              labels(first: 10) {\n",
    "                edges {\n",
    "                  node {\n",
    "                    name\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              body\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        pageInfo {\n",
    "          endCursor\n",
    "          hasNextPage\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b32e41-7d3f-458b-ad0f-0c13d3146813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_contributor_count(repo_owner, repo_name):\n",
    "#     global current_token\n",
    "#     max_retries = 3\n",
    "#     retries = 0\n",
    "#     while retries < max_retries:\n",
    "#         try:\n",
    "#             # Randomize User-Agent for each query\n",
    "#             headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "#             headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "#             url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contributors?per_page=1&anon=true\"\n",
    "#             response = requests.get(url, headers=headers)\n",
    "#             if response.status_code == 200:\n",
    "#                 return int(response.headers.get(\"Link\", \"\").split(\",\")[-1].split(\"&page=\")[-1].split(\">\")[0]) if \"Link\" in response.headers else len(response.json())\n",
    "#             elif response.status_code == 403:\n",
    "#                 print(f\"Rate limit exceeded, switching token... (Attempt {retries + 1}/{max_retries})\")\n",
    "#                 current_token = next(token_iterator)\n",
    "#                 retries += 1\n",
    "#             else:\n",
    "#                 response.raise_for_status()\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error: {e}, retrying... (Attempt {retries + 1}/{max_retries})\")\n",
    "#             retries += 1\n",
    "#     raise Exception(\"Max retries reached. Unable to complete the request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c2427-7797-4088-a144-6045c87ee349",
   "metadata": {},
   "outputs": [],
   "source": [
    "transport.headers = headers\n",
    "# Check rate limit before executing the main query\n",
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "rate_limit_response = client.execute(rate_limit_query)\n",
    "print(f\"Rate limit: {rate_limit_response['rateLimit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49acb9fd-7a25-458d-aec7-8f302a653c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def execute_query(keyword, first=100, after_cursor=None):\n",
    "    global current_token\n",
    "    print(\n",
    "        f\"Executing query with keyword: {keyword}, first: {first}, afterCursor: {after_cursor}\"\n",
    "    )\n",
    "    while True:\n",
    "        try:\n",
    "            # Randomize User-Agent for each query\n",
    "            headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "            transport.headers = headers\n",
    "            # Check rate limit before executing the main query\n",
    "            rate_limit_response = client.execute(rate_limit_query)\n",
    "            remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "            if remaining < 100:\n",
    "                print(\n",
    "                    f\"Rate limit remaining ({remaining}) is below threshold. Switching token...\"\n",
    "                )\n",
    "                # Set up to track whether we have cycled through all tokens\n",
    "                all_tokens_checked = False\n",
    "                initial_token = current_token\n",
    "\n",
    "                while not all_tokens_checked:\n",
    "                    # Switch to the next token\n",
    "                    current_token = next(token_iterator)\n",
    "                    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "                    transport.headers = headers\n",
    "\n",
    "                    # Check the rate limit of the new token\n",
    "                    rate_limit_response = client.execute(rate_limit_query)\n",
    "                    remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "\n",
    "                    if remaining >= 100:\n",
    "                        print(\n",
    "                            f\"Switched to a new token with sufficient rate limit ({remaining} remaining).\"\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    # Check if we have cycled through all tokens\n",
    "                    if current_token == initial_token:\n",
    "                        print(\"All tokens are below threshold. Waiting for 1 hour...\")\n",
    "                        time.sleep(3600)\n",
    "                        all_tokens_checked = True\n",
    "\n",
    "                continue\n",
    "            return client.execute(\n",
    "                query_template,\n",
    "                variable_values={\n",
    "                    \"keyword\": keyword,\n",
    "                    \"first\": first,\n",
    "                    \"afterCursor\": after_cursor,\n",
    "                },\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if \"API rate limit\" in str(e):\n",
    "                print(\n",
    "                    f\"Rate limit reached: {e}, switching token... (Attempt with first {first})\"\n",
    "                )\n",
    "                current_token = next(token_iterator)\n",
    "                headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "            else:\n",
    "                if first > 1:\n",
    "                    first = max(1, first // 2)\n",
    "                    print(\n",
    "                        f\"Error: {e}, reducing number of results and retrying... (Attempt with first {first})\"\n",
    "                    )\n",
    "                else:\n",
    "                    break\n",
    "    print(\"Max retries reached. Sleeping for 60 minutes and switching token...\")\n",
    "    time.sleep(3600)\n",
    "    current_token = next(token_iterator)\n",
    "    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "    transport.headers = headers\n",
    "    return execute_query(keyword, first, after_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10e2f9a0-95df-4b00-8544-efeb1ba4d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if os.path.exists(\"progress.pkl\"):\n",
    "    with open(\"progress.pkl\", \"rb\") as f:\n",
    "        progress_data = pickle.load(f)\n",
    "        df = progress_data[\"df\"]\n",
    "        start_index = progress_data[\"start_index\"]\n",
    "else:\n",
    "    df = []\n",
    "    start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69df882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb89147-ab2c-4654-a8d7-637737c90537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from os import close\n",
    "\n",
    "# template\n",
    "keywords = [\"spam\"]\n",
    "index = start_index\n",
    "se_fm_repository_data = df\n",
    "for keyword in tqdm(keywords):\n",
    "    search_keyword = f\"label:{keyword} is:pr is:public comments:>10 archived:false created:2020-01-30..2024-01-30\"\n",
    "    try:\n",
    "        after_cursor = None\n",
    "        while True:\n",
    "            response = execute_query(\n",
    "                search_keyword, first=10, after_cursor=after_cursor\n",
    "            )\n",
    "            if response[\"search\"][\"issueCount\"] == 0:\n",
    "                break\n",
    "            # Extract pr\n",
    "            for edge in response[\"search\"][\"edges\"]:\n",
    "                pull_request = edge[\"node\"]\n",
    "\n",
    "                if not pull_request:\n",
    "                    continue\n",
    "                timeline = pull_request[\"timeline\"][\"edges\"]\n",
    "                labeled_spam_event = next(\n",
    "                    filter(\n",
    "                        lambda x: x[\"node\"]\n",
    "                        and x[\"node\"][\"__typename\"] == \"LabeledEvent\"\n",
    "                        and x[\"node\"][\"label\"][\"name\"]\n",
    "                        and (x[\"node\"][\"label\"][\"name\"]).lower() == \"spam\",\n",
    "                        timeline,\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "                labeled_spam_event_node = (\n",
    "                    labeled_spam_event[\"node\"] if labeled_spam_event else None\n",
    "                )\n",
    "                closed_event = next(\n",
    "                    filter(\n",
    "                        lambda x: x[\"node\"]\n",
    "                        and x[\"node\"][\"__typename\"] == \"ClosedEvent\",\n",
    "                        timeline,\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "                closed_event_node = closed_event[\"node\"] if closed_event else None\n",
    "                author = pull_request[\"author\"]\n",
    "                comments = [\n",
    "                    comment[\"node\"] for comment in pull_request[\"comments\"][\"edges\"]\n",
    "                ]\n",
    "                labeled_spam_at = (\n",
    "                    labeled_spam_event_node[\"createdAt\"]\n",
    "                    if labeled_spam_event_node\n",
    "                    else None\n",
    "                )\n",
    "\n",
    "                labeled_spam_by = (\n",
    "                    labeled_spam_event_node[\"actor\"][\"login\"]\n",
    "                    if labeled_spam_event_node and labeled_spam_event_node[\"actor\"]\n",
    "                    else None\n",
    "                )\n",
    "                comments_by_spam_labeler = [\n",
    "                    {**labeler_comment, \"commented_before_labeling_spam\": labeler_comment[\"createdAt\"] < labeled_spam_at}\n",
    "                    for labeler_comment in comments\n",
    "                    if (\n",
    "                        (\n",
    "                            labeler_comment[\"author\"]\n",
    "                            and labeler_comment[\"author\"][\"login\"] == labeled_spam_by\n",
    "                        )\n",
    "                        or (not labeler_comment[\"author\"] and not labeled_spam_by)\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "                df.append(\n",
    "                    {\n",
    "                        \"id\": pull_request[\"id\"],\n",
    "                        \"title\": pull_request[\"title\"],\n",
    "                        \"url\": pull_request[\"url\"],\n",
    "                        \"state\": pull_request[\"state\"],\n",
    "                        \"comments_count\": pull_request[\"comments\"][\"totalCount\"],\n",
    "                        # \"comments\": comments,\n",
    "                        \"comments_by_spam_labeler_count\": len(comments_by_spam_labeler),\n",
    "                        \"comments_by_spam_labeler\": comments_by_spam_labeler,\n",
    "                        \"labeled_spam_by\": (\n",
    "                            labeled_spam_event_node[\"actor\"][\"login\"]\n",
    "                            if labeled_spam_event_node\n",
    "                            and labeled_spam_event_node[\"actor\"]\n",
    "                            else None\n",
    "                        ),\n",
    "                        \"is_labeled_spam_by_bot\": labeled_spam_by is None,\n",
    "                        \"labeled_spam_at\": labeled_spam_at,\n",
    "                        \"closed_by\": (\n",
    "                            closed_event_node[\"actor\"][\"login\"]\n",
    "                            if closed_event_node and closed_event_node[\"actor\"]\n",
    "                            else None\n",
    "                        ),\n",
    "                        \"closed_at\": (\n",
    "                            closed_event_node[\"createdAt\"]\n",
    "                            if closed_event_node\n",
    "                            else None\n",
    "                        ),\n",
    "                        \"merged\": pull_request[\"merged\"],\n",
    "                        \"body\": pull_request[\"body\"],\n",
    "                        \"created_at\": pull_request[\"createdAt\"],\n",
    "                        \"updated_at\": pull_request[\"updatedAt\"],\n",
    "                        \"repository\": pull_request[\"repository\"],\n",
    "                        \"merge_commit\": (\n",
    "                            pull_request[\"mergeCommit\"][\"oid\"]\n",
    "                            if pull_request[\"mergeCommit\"]\n",
    "                            else None\n",
    "                        ),\n",
    "                        \"labels\": [\n",
    "                            label[\"node\"][\"name\"]\n",
    "                            for label in pull_request[\"labels\"][\"edges\"]\n",
    "                        ],\n",
    "                        \"commits_count\": pull_request[\"commits\"][\"totalCount\"],\n",
    "                        \"changed_files_count\": pull_request[\"changedFiles\"],\n",
    "                        \"commits\": pull_request[\"commits\"][\"edges\"],\n",
    "                        \"author_name\": (author[\"login\"] if author else None),\n",
    "                        \"author_url\": (author[\"url\"] if author else None),\n",
    "                        \"author_repository_count\": (\n",
    "                            author[\"repositories\"][\"totalCount\"]\n",
    "                            if author and author[\"repositories\"]\n",
    "                            else None\n",
    "                        ),\n",
    "                        \"author_contributions_count\": (\n",
    "                            author[\"contributionsCollection\"][\"contributionCalendar\"][\n",
    "                                \"totalContributions\"\n",
    "                            ]\n",
    "                            if author\n",
    "                            and author[\"contributionsCollection\"]\n",
    "                            and author[\"contributionsCollection\"][\n",
    "                                \"contributionCalendar\"\n",
    "                            ]\n",
    "                            else None\n",
    "                        ),\n",
    "                        \"author_followers_count\": (\n",
    "                            author[\"followers\"][\"totalCount\"]\n",
    "                            if author and author[\"followers\"]\n",
    "                            else None\n",
    "                        ),\n",
    "                        \"author_following_count\": (\n",
    "                            author[\"following\"][\"totalCount\"]\n",
    "                            if author and author[\"following\"]\n",
    "                            else None\n",
    "                        ),\n",
    "                        # \"watchers\": repo[\"watchers\"][\"totalCount\"],\n",
    "                        # \"open_issues\": repo[\"issues\"][\"totalCount\"],\n",
    "                        # \"closed_issues\": repo[\"issuesClosed\"][\"totalCount\"],\n",
    "                        # \"total_issues\": repo[\"issues\"][\"totalCount\"]\n",
    "                        # + repo[\"issuesClosed\"][\"totalCount\"],\n",
    "                        # \"open_pull_requests\": repo[\"pullRequests\"][\"totalCount\"],\n",
    "                        # \"closed_pull_requests\": repo[\"pullRequestsClosed\"][\n",
    "                        #     \"totalCount\"\n",
    "                        # ],\n",
    "                        # \"total_pull_requests\": repo[\"pullRequests\"][\"totalCount\"]\n",
    "                        # + repo[\"pullRequestsClosed\"][\"totalCount\"],\n",
    "                        # \"commits\": repo[\"defaultBranchRef\"][\"target\"][\"history\"][\n",
    "                        #     \"totalCount\"\n",
    "                        # ],\n",
    "                        # \"last_commit\": repo[\"pushedAt\"],\n",
    "                        # \"releases\": repo[\"releases\"][\"totalCount\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # Pagination\n",
    "            page_info = response[\"search\"][\"pageInfo\"]\n",
    "            if page_info[\"hasNextPage\"]:\n",
    "                after_cursor = page_info[\"endCursor\"]\n",
    "            else:\n",
    "                break\n",
    "        with open(\"progress.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\"df\": se_fm_repository_data, \"start_index\": index + 1}, f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data for keywords '{keyword}': {e}\")\n",
    "        # Save progress before terminating\n",
    "        with open(\"progress.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\"df\": df, \"start_index\": index}, f)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_pkl_content(filepath):\n",
    "    \"\"\"\n",
    "    Loads and displays the content of a .pkl (pickle) file in a Jupyter Notebook.\n",
    "    Handles different data structures within the pickle file and provides informative output.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        print(f\"Content of {filepath}:\\n\")\n",
    "\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            print(\"Data is a Pandas DataFrame:\")\n",
    "            print(\n",
    "                data.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\")\n",
    "            )  # Display first few rows as a Markdown table\n",
    "            print(\"\\nDataFrame Info:\")\n",
    "            data.info()  # Display DataFrame information\n",
    "        elif isinstance(data, list):\n",
    "            print(\"Data is a List:\")\n",
    "            if all(\n",
    "                isinstance(item, dict) for item in data\n",
    "            ):  # Check if list contains dictionaries\n",
    "                df = pd.DataFrame(data)\n",
    "                print(\n",
    "                    df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\")\n",
    "                )  # Display first few rows as a Markdown table\n",
    "                print(\"\\nDataFrame Info:\")\n",
    "                df.info()  # Display DataFrame information\n",
    "            else:\n",
    "                print(data[:10])  # Print first 10 items if not dictionaries\n",
    "                print(f\"\\nList Length: {len(data)}\")\n",
    "        elif isinstance(data, dict):\n",
    "            print(\"Data is a Dictionary:\")\n",
    "            pd.DataFrame(data[\"df\"]).to_csv(\"spam_data.csv\", index=True)\n",
    "            filename = \"spam_data.json\"\n",
    "            try:\n",
    "                with open(filename, \"w\") as f:\n",
    "                    json.dump(data['df'], f, indent=4)\n",
    "                print(f\"Data written to {filename} successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "            for key, value in data.items():\n",
    "                print(f\"\\nKey: {key}\")\n",
    "                if isinstance(value, pd.DataFrame):\n",
    "                    print(\"Value is a Pandas DataFrame:\")\n",
    "                    print(\n",
    "                        value.head().to_markdown(\n",
    "                            index=False, numalign=\"left\", stralign=\"left\"\n",
    "                        )\n",
    "                    )\n",
    "                    print(\"\\nDataFrame Info:\")\n",
    "                    value.info()\n",
    "                elif isinstance(value, list):\n",
    "                    print(\"Value is a List:\")\n",
    "                    print(value[:10])\n",
    "                    print(f\"\\nList Length: {len(value)}\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"Value: {value}\")\n",
    "        elif isinstance(data, set):\n",
    "            print(\"Data is a Set:\")\n",
    "            print(list(data)[:10])\n",
    "            print(f\"\\nSet Length: {len(data)}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Data is of type: {type(data)}\")\n",
    "            print(data)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "    except pickle.UnpicklingError:\n",
    "        print(\n",
    "            f\"Error: Could not unpickle data from {filepath}. The file might be corrupted or use a different pickle protocol.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "filepath = \"progress.pkl\"  # Replace with the actual path to your .pkl file\n",
    "display_pkl_content(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469812ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
