{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4babdda8-11f7-485e-bad8-d8c5b8eebb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current token: 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\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "from datetime import datetime\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Read tokens from a text file\n",
    "tokens_file = \"./env/tokens.txt\"\n",
    "with open(tokens_file, \"r\") as file:\n",
    "    tokens = file.read().splitlines()\n",
    "\n",
    "# Create an iterator to cycle through the tokens\n",
    "token_iterator = itertools.cycle(tokens)\n",
    "current_token = next(token_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c281d1-993b-497b-8984-0e32ac6a61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of User-Agents for randomization\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\"\n",
    "]\n",
    "\n",
    "# Define headers to authenticate using the first token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {current_token}\",\n",
    "    \"User-Agent\": random.choice(user_agents)\n",
    "}\n",
    "\n",
    "# Setup GraphQL endpoint and client\n",
    "graphql_url = \"https://api.github.com/graphql\"\n",
    "transport = RequestsHTTPTransport(url=graphql_url, headers=headers, use_json=True)\n",
    "client = Client(transport=transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5062f1b0-a9df-4f94-bb18-56f42774bc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1/1 is valid. Logged in as: JosephAyo\n"
     ]
    }
   ],
   "source": [
    "# Test all tokens to verify their validity\n",
    "def test_all_tokens():\n",
    "    test_query = gql(\n",
    "        \"\"\"\n",
    "        {\n",
    "          viewer {\n",
    "            login\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "    )\n",
    "    for i, token in enumerate(tokens):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"User-Agent\": random.choice(user_agents)\n",
    "        }\n",
    "        transport = RequestsHTTPTransport(url=graphql_url, headers=headers, use_json=True)\n",
    "        client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "        \n",
    "        try:\n",
    "            response = client.execute(test_query)\n",
    "            print(f\"Token {i+1}/{len(tokens)} is valid. Logged in as: {response['viewer']['login']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Token {i+1}/{len(tokens)} failed with error: {e}\")\n",
    "\n",
    "# Run the token validation\n",
    "test_all_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd85df0-71b7-46c8-9ed4-eceb724201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphQL query\n",
    "query_template = gql(\n",
    "    \"\"\"\n",
    "    query searchRepositories($keyword: String!, $afterCursor: String, $first: Int) {\n",
    "      search(query: $keyword, type: REPOSITORY, first: $first, after: $afterCursor) {\n",
    "        repositoryCount\n",
    "        edges {\n",
    "          cursor\n",
    "          node {\n",
    "            ... on Repository {\n",
    "              name\n",
    "              description\n",
    "              repositoryTopics(first: 100) {\n",
    "                            edges {\n",
    "                                node {\n",
    "                                    topic {\n",
    "                                        name\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "              url\n",
    "              stargazers {\n",
    "                totalCount\n",
    "              }\n",
    "              forks {\n",
    "                totalCount\n",
    "              }\n",
    "              watchers {\n",
    "                totalCount\n",
    "              }\n",
    "              issues(states: OPEN) {\n",
    "                totalCount\n",
    "              }\n",
    "              issuesClosed: issues(states: CLOSED) {\n",
    "                totalCount\n",
    "              }\n",
    "              pullRequests(states: OPEN) {\n",
    "                totalCount\n",
    "              }\n",
    "              pullRequestsClosed: pullRequests(states: CLOSED) {\n",
    "                totalCount\n",
    "              }\n",
    "              defaultBranchRef {\n",
    "                target {\n",
    "                  ... on Commit {\n",
    "                    history {\n",
    "                      totalCount\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              createdAt\n",
    "              pushedAt\n",
    "              releases {\n",
    "                totalCount\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        pageInfo {\n",
    "          endCursor\n",
    "          hasNextPage\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b32e41-7d3f-458b-ad0f-0c13d3146813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_contributor_count(repo_owner, repo_name):\n",
    "#     global current_token\n",
    "#     max_retries = 3\n",
    "#     retries = 0\n",
    "#     while retries < max_retries:\n",
    "#         try:\n",
    "#             # Randomize User-Agent for each query\n",
    "#             headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "#             headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "#             url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contributors?per_page=1&anon=true\"\n",
    "#             response = requests.get(url, headers=headers)\n",
    "#             if response.status_code == 200:\n",
    "#                 return int(response.headers.get(\"Link\", \"\").split(\",\")[-1].split(\"&page=\")[-1].split(\">\")[0]) if \"Link\" in response.headers else len(response.json())\n",
    "#             elif response.status_code == 403:\n",
    "#                 print(f\"Rate limit exceeded, switching token... (Attempt {retries + 1}/{max_retries})\")\n",
    "#                 current_token = next(token_iterator)\n",
    "#                 retries += 1\n",
    "#             else:\n",
    "#                 response.raise_for_status()\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error: {e}, retrying... (Attempt {retries + 1}/{max_retries})\")\n",
    "#             retries += 1\n",
    "#     raise Exception(\"Max retries reached. Unable to complete the request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2c2427-7797-4088-a144-6045c87ee349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit: {'limit': 5000, 'remaining': 4988, 'used': 12, 'resetAt': '2025-01-09T20:03:32Z'}\n"
     ]
    }
   ],
   "source": [
    "transport.headers = headers\n",
    "# Check rate limit before executing the main query\n",
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "rate_limit_response = client.execute(rate_limit_query)\n",
    "print(f\"Rate limit: {rate_limit_response['rateLimit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49acb9fd-7a25-458d-aec7-8f302a653c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "def execute_query(keyword, first=100, after_cursor=None):\n",
    "    global current_token\n",
    "    while True:\n",
    "        try:\n",
    "            # Randomize User-Agent for each query\n",
    "            headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "            transport.headers = headers\n",
    "            # Check rate limit before executing the main query\n",
    "            rate_limit_response = client.execute(rate_limit_query)\n",
    "            remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "            if remaining < 100:\n",
    "                print(f\"Rate limit remaining ({remaining}) is below threshold. Switching token...\")\n",
    "                # Set up to track whether we have cycled through all tokens\n",
    "                all_tokens_checked = False\n",
    "                initial_token = current_token\n",
    "            \n",
    "                while not all_tokens_checked:\n",
    "                    # Switch to the next token\n",
    "                    current_token = next(token_iterator)\n",
    "                    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "                    transport.headers = headers\n",
    "                    \n",
    "                    # Check the rate limit of the new token\n",
    "                    rate_limit_response = client.execute(rate_limit_query)\n",
    "                    remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "            \n",
    "                    if remaining >= 100:\n",
    "                        print(f\"Switched to a new token with sufficient rate limit ({remaining} remaining).\")\n",
    "                        break\n",
    "            \n",
    "                    # Check if we have cycled through all tokens\n",
    "                    if current_token == initial_token:\n",
    "                        print(\"All tokens are below threshold. Waiting for 1 hour...\")\n",
    "                        time.sleep(3600)\n",
    "                        all_tokens_checked = True\n",
    "            \n",
    "                continue\n",
    "            return client.execute(query_template, variable_values={\"keyword\": keyword, \"first\": first, \"afterCursor\": after_cursor})\n",
    "        except Exception as e:\n",
    "            if \"API rate limit\" in str(e):\n",
    "                print(f\"Rate limit reached: {e}, switching token... (Attempt with first {first})\")\n",
    "                current_token = next(token_iterator)\n",
    "                headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "            else:\n",
    "                if first > 1:\n",
    "                    first = max(1, first // 2)\n",
    "                    print(f\"Error: {e}, reducing number of results and retrying... (Attempt with first {first})\")\n",
    "                else:\n",
    "                    break\n",
    "    print(\"Max retries reached. Sleeping for 60 minutes and switching token...\")\n",
    "    time.sleep(3600)\n",
    "    current_token = next(token_iterator)\n",
    "    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "    transport.headers = headers\n",
    "    return execute_query(keyword, first, after_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10e2f9a0-95df-4b00-8544-efeb1ba4d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if os.path.exists('progress.pkl'):\n",
    "    with open('progress.pkl', 'rb') as f:\n",
    "        progress_data = pickle.load(f)\n",
    "        df = progress_data['df']\n",
    "        start_index = progress_data['start_index']\n",
    "else:\n",
    "    df = []\n",
    "    start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb89147-ab2c-4654-a8d7-637737c90537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# template\n",
    "keywords = ['spam']\n",
    "for keyword in tqdm(keywords):\n",
    "    search_keyword = f'\"{keyword}\" in:name,readme,description,topics created:>=2022-11-30 fork:false is:public archived:false size:>0 stars:>=5 sort:stars-desc'\n",
    "    try:\n",
    "        after_cursor = None\n",
    "        while True:\n",
    "            response = execute_query(search_keyword, first=100, after_cursor=after_cursor)\n",
    "            if response['search']['repositoryCount'] == 0:\n",
    "                break\n",
    "            # Extract repositories\n",
    "            for edge in response['search']['edges']:\n",
    "                repo = edge['node']\n",
    "                df.append({\n",
    "                    \"name\": repo[\"name\"],\n",
    "                    \"description\": repo[\"description\"],\n",
    "                    \"url\": repo[\"url\"],\n",
    "                    \"topics\": [topic[\"node\"][\"topic\"][\"name\"] for topic in repo[\"repositoryTopics\"][\"edges\"]],\n",
    "                    \"stars\": repo[\"stargazers\"][\"totalCount\"],\n",
    "                    \"forks\": repo[\"forks\"][\"totalCount\"],\n",
    "                    \"watchers\": repo[\"watchers\"][\"totalCount\"],\n",
    "                    \"open_issues\": repo[\"issues\"][\"totalCount\"],\n",
    "                    \"closed_issues\": repo[\"issuesClosed\"][\"totalCount\"],\n",
    "                    \"total_issues\": repo[\"issues\"][\"totalCount\"] + repo[\"issuesClosed\"][\"totalCount\"],\n",
    "                    \"open_pull_requests\": repo[\"pullRequests\"][\"totalCount\"],\n",
    "                    \"closed_pull_requests\": repo[\"pullRequestsClosed\"][\"totalCount\"],\n",
    "                    \"total_pull_requests\": repo[\"pullRequests\"][\"totalCount\"] + repo[\"pullRequestsClosed\"][\"totalCount\"],\n",
    "                    \"commits\": repo[\"defaultBranchRef\"][\"target\"][\"history\"][\"totalCount\"],\n",
    "                    \"created_at\": repo[\"createdAt\"],\n",
    "                    \"last_commit\": repo[\"pushedAt\"],\n",
    "                    \"releases\": repo[\"releases\"][\"totalCount\"]\n",
    "                })\n",
    "\n",
    "            # Pagination\n",
    "            page_info = response['search']['pageInfo']\n",
    "            if page_info['hasNextPage']:\n",
    "                after_cursor = page_info['endCursor']\n",
    "            else:\n",
    "                break\n",
    "        with open('progress.pkl', 'wb') as f:\n",
    "            pickle.dump({'df': se_fm_repository_data, 'start_index': index + 1}, f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data for keywords '{keyword}': {e}\")\n",
    "        # Save progress before terminating\n",
    "        with open('progress.pkl', 'wb') as f:\n",
    "            pickle.dump({'df': df, 'start_index': index}, f)\n",
    "        raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
