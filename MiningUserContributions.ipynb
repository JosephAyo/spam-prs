{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4babdda8-11f7-485e-bad8-d8c5b8eebb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import datetime\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Read tokens from a text file\n",
    "tokens_file = \"./env/tokens.txt\"\n",
    "with open(tokens_file, \"r\") as file:\n",
    "    tokens = file.read().splitlines()\n",
    "\n",
    "# Create an iterator to cycle through the tokens\n",
    "token_iterator = itertools.cycle(tokens)\n",
    "current_token = next(token_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0c281d1-993b-497b-8984-0e32ac6a61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of User-Agents for randomization\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "]\n",
    "\n",
    "# Define headers to authenticate using the first token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {current_token}\",\n",
    "    \"User-Agent\": random.choice(user_agents),\n",
    "}\n",
    "\n",
    "# Setup GraphQL endpoint and client\n",
    "graphql_url = \"https://api.github.com/graphql\"\n",
    "transport = RequestsHTTPTransport(url=graphql_url, headers=headers, use_json=True)\n",
    "client = Client(transport=transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5422f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_activity(activity: str):\n",
    "    log = f\"{datetime.datetime.now()}: {activity}\\n\"\n",
    "    # print(log)\n",
    "    with open(\"user-contributions-output.log\", \"a\") as log_file:\n",
    "        log_file.write(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062f1b0-a9df-4f94-bb18-56f42774bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all tokens to verify their validity\n",
    "def test_all_tokens():\n",
    "    test_query = gql(\n",
    "        \"\"\"\n",
    "        {\n",
    "          viewer {\n",
    "            login\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "    )\n",
    "    for i, token in enumerate(tokens):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"User-Agent\": random.choice(user_agents),\n",
    "        }\n",
    "        transport = RequestsHTTPTransport(\n",
    "            url=graphql_url, headers=headers, use_json=True\n",
    "        )\n",
    "        client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "\n",
    "        try:\n",
    "            response = client.execute(test_query)\n",
    "            log_activity(\n",
    "                f\"Token {i+1}/{len(tokens)} is valid. Logged in as: {response['viewer']['login']}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            log_activity(f\"Token {i+1}/{len(tokens)} failed with error: {e}\")\n",
    "\n",
    "\n",
    "# Run the token validation\n",
    "test_all_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdd85df0-71b7-46c8-9ed4-eceb724201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphQL query\n",
    "query_template = gql(\n",
    "    \"\"\"\n",
    "      query($username: String!, $start: DateTime!, $end: DateTime!) {\n",
    "        user(login: $username) {\n",
    "          url\n",
    "          contributionsCollection(from: $start, to: $end) {\n",
    "            contributionCalendar {\n",
    "              totalContributions\n",
    "            }\n",
    "            totalCommitContributions\n",
    "            totalIssueContributions\n",
    "            totalPullRequestContributions\n",
    "            totalPullRequestReviewContributions\n",
    "            totalRepositoriesWithContributedCommits\n",
    "            totalRepositoriesWithContributedIssues\n",
    "            totalRepositoriesWithContributedPullRequestReviews\n",
    "            totalRepositoriesWithContributedPullRequests\n",
    "            totalRepositoryContributions\n",
    "            restrictedContributionsCount\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c2427-7797-4088-a144-6045c87ee349",
   "metadata": {},
   "outputs": [],
   "source": [
    "transport.headers = headers\n",
    "# Check rate limit before executing the main query\n",
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "rate_limit_response = client.execute(rate_limit_query)\n",
    "log_activity(f\"Rate limit: {rate_limit_response['rateLimit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acb9fd-7a25-458d-aec7-8f302a653c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def execute_query(username, start=100, end=None):\n",
    "    global current_token\n",
    "    log_activity(\n",
    "        f\"Executing query with username: {username}, start: {start}, afterCursor: {end}\"\n",
    "    )\n",
    "    while True:\n",
    "        try:\n",
    "            # Randomize User-Agent for each query\n",
    "            headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "            transport.headers = headers\n",
    "            # Check rate limit before executing the main query\n",
    "            rate_limit_response = client.execute(rate_limit_query)\n",
    "            remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "            if remaining < 100:\n",
    "                log_activity(\n",
    "                    f\"Rate limit remaining ({remaining}) is below threshold. Switching token...\"\n",
    "                )\n",
    "                # Set up to track whether we have cycled through all tokens\n",
    "                all_tokens_checked = False\n",
    "                initial_token = current_token\n",
    "\n",
    "                while not all_tokens_checked:\n",
    "                    # Switch to the next token\n",
    "                    current_token = next(token_iterator)\n",
    "                    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "                    transport.headers = headers\n",
    "\n",
    "                    # Check the rate limit of the new token\n",
    "                    rate_limit_response = client.execute(rate_limit_query)\n",
    "                    remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "\n",
    "                    if remaining >= 100:\n",
    "                        log_activity(\n",
    "                            f\"Switched to a new token with sufficient rate limit ({remaining} remaining).\"\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    # Check if we have cycled through all tokens\n",
    "                    if current_token == initial_token:\n",
    "                        log_activity(\"All tokens are below threshold. Waiting for 1 hour...\")\n",
    "                        time.sleep(3600)\n",
    "                        all_tokens_checked = True\n",
    "\n",
    "                continue\n",
    "            return client.execute(\n",
    "                query_template,\n",
    "                variable_values={\n",
    "                    \"username\": username,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                },\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if \"API rate limit\" in str(e):\n",
    "                log_activity(\n",
    "                    f\"Rate limit reached: {e}, switching token... (Attempt with first {first})\"\n",
    "                )\n",
    "                current_token = next(token_iterator)\n",
    "                headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "            else:\n",
    "                if first > 1:\n",
    "                    first = max(1, first // 2)\n",
    "                    log_activity(\n",
    "                    f\"Error: {e}, reducing number of results and retrying... (Attempt with first {first})\"\n",
    "                    )\n",
    "                else:\n",
    "                    log_activity(f\"Query failed completely after retries: {e}\")\n",
    "                    break\n",
    "    log_activity(\"Max retries reached. Sleeping for 30 minutes and switching token...\")\n",
    "    time.sleep(1800)\n",
    "    current_token = next(token_iterator)\n",
    "    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "    transport.headers = headers\n",
    "    return execute_query(username, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10e2f9a0-95df-4b00-8544-efeb1ba4d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if os.path.exists(\"seg_user_contribution_count_progress.pkl\"):\n",
    "    with open(\"seg_user_contribution_count_progress.pkl\", \"rb\") as f:\n",
    "        progress_data = pickle.load(f)\n",
    "        df = progress_data[\"df\"]\n",
    "        start_index = progress_data[\"start_index\"]\n",
    "else:\n",
    "    df = []\n",
    "    start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_str(date: str):\n",
    "    return datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def get_serializable_date_str(date: datetime.datetime):\n",
    "    try:\n",
    "        return date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    except Exception as e:\n",
    "        log_activity(f\"Error: {e},\\n date:{date}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb89147-ab2c-4654-a8d7-637737c90537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df = []\n",
    "start_index = 0\n",
    "\n",
    "index = start_index\n",
    "user_contribution_data = df\n",
    "current_date = datetime.datetime.now()\n",
    "all_contributions = {}\n",
    "with open(\"progress.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    spam_prs = data[\"df\"]\n",
    "    for pr in spam_prs:\n",
    "        try:\n",
    "\n",
    "            pr_id = pr.get(\"id\")\n",
    "            username = pr.get(\"author_name\")\n",
    "            author_account_created_at = pr.get(\"author_account_created_at\")\n",
    "\n",
    "            if not username or not pr_id or not author_account_created_at:\n",
    "                continue\n",
    "\n",
    "            author_account_created_at = get_datetime_str(author_account_created_at)\n",
    "            pr_created_at = get_datetime_str(pr.get(\"created_at\"))\n",
    "            pr_labeled_spam_at = get_datetime_str(pr.get(\"labeled_spam_at\"))\n",
    "\n",
    "            user_query_start_date = author_account_created_at\n",
    "            is_contribution_before_spam_label = True\n",
    "\n",
    "            # counts before spam label\n",
    "            total_contributions_count_before_spam_label = 0\n",
    "            total_commit_contributions_before_spam_label = 0\n",
    "            total_issue_contributions_before_spam_label = 0\n",
    "            total_pull_request_contributions_before_spam_label = 0\n",
    "            total_pull_request_review_contributions_before_spam_label = 0\n",
    "            total_repositories_with_contributed_commits_before_spam_label = 0\n",
    "            total_repositories_with_contributed_issues_before_spam_label = 0\n",
    "            total_repositories_with_contributed_pull_request_reviews_before_spam_label = 0\n",
    "            total_repositories_with_contributed_pull_requests_before_spam_label = 0\n",
    "            total_repository_contributions_before_spam_label = 0\n",
    "            restricted_contributions_count_before_spam_label = 0\n",
    "\n",
    "            # counts after spam label\n",
    "            total_contributions_count_after_spam_label = 0\n",
    "            total_commit_contributions_after_spam_label = 0\n",
    "            total_issue_contributions_after_spam_label = 0\n",
    "            total_pull_request_contributions_after_spam_label = 0\n",
    "            total_pull_request_review_contributions_after_spam_label = 0\n",
    "            total_repositories_with_contributed_commits_after_spam_label = 0\n",
    "            total_repositories_with_contributed_issues_after_spam_label = 0\n",
    "            total_repositories_with_contributed_pull_request_reviews_after_spam_label = 0\n",
    "            total_repositories_with_contributed_pull_requests_after_spam_label = 0\n",
    "            total_repository_contributions_after_spam_label = 0\n",
    "            restricted_contributions_count_after_spam_label = 0\n",
    "            while True:\n",
    "                one_year_from_start_date = user_query_start_date + datetime.timedelta(\n",
    "                    days=365\n",
    "                )\n",
    "\n",
    "                if not is_contribution_before_spam_label:\n",
    "                    user_query_end_date = min(one_year_from_start_date, current_date)\n",
    "                else:\n",
    "                    user_query_end_date = min(one_year_from_start_date, pr_labeled_spam_at)\n",
    "\n",
    "                try:\n",
    "                    response = execute_query(\n",
    "                        username,\n",
    "                        start=get_serializable_date_str(user_query_start_date),\n",
    "                        end=get_serializable_date_str(user_query_end_date),\n",
    "                    )\n",
    "                    contributionsCollection = response[\"user\"][\"contributionsCollection\"]\n",
    "\n",
    "                    contributions_count = contributionsCollection[\"contributionCalendar\"][\n",
    "                        \"totalContributions\"\n",
    "                    ]\n",
    "                    total_commit_contributions = contributionsCollection[\n",
    "                        \"totalCommitContributions\"\n",
    "                    ]\n",
    "                    total_issue_contributions = contributionsCollection[\n",
    "                        \"totalIssueContributions\"\n",
    "                    ]\n",
    "                    total_pull_request_contributions = contributionsCollection[\n",
    "                        \"totalPullRequestContributions\"\n",
    "                    ]\n",
    "                    total_pull_request_review_contributions = contributionsCollection[\n",
    "                        \"totalPullRequestReviewContributions\"\n",
    "                    ]\n",
    "                    total_repositories_with_contributed_commits = contributionsCollection[\n",
    "                        \"totalRepositoriesWithContributedCommits\"\n",
    "                    ]\n",
    "                    total_repositories_with_contributed_issues = contributionsCollection[\n",
    "                        \"totalRepositoriesWithContributedIssues\"\n",
    "                    ]\n",
    "                    total_repositories_with_contributed_pull_request_reviews = (\n",
    "                        contributionsCollection[\n",
    "                            \"totalRepositoriesWithContributedPullRequestReviews\"\n",
    "                        ]\n",
    "                    )\n",
    "                    total_repositories_with_contributed_pull_requests = (\n",
    "                        contributionsCollection[\n",
    "                            \"totalRepositoriesWithContributedPullRequests\"\n",
    "                        ]\n",
    "                    )\n",
    "                    total_repository_contributions = contributionsCollection[\n",
    "                        \"totalRepositoryContributions\"\n",
    "                    ]\n",
    "                    restricted_contributions_count = contributionsCollection[\n",
    "                        \"restrictedContributionsCount\"\n",
    "                    ]\n",
    "                    if is_contribution_before_spam_label:\n",
    "                        total_contributions_count_before_spam_label += contributions_count\n",
    "                        total_commit_contributions_before_spam_label += (\n",
    "                            total_commit_contributions\n",
    "                        )\n",
    "                        total_issue_contributions_before_spam_label += (\n",
    "                            total_issue_contributions\n",
    "                        )\n",
    "                        total_pull_request_contributions_before_spam_label += (\n",
    "                            total_pull_request_contributions\n",
    "                        )\n",
    "                        total_pull_request_review_contributions_before_spam_label += (\n",
    "                            total_pull_request_review_contributions\n",
    "                        )\n",
    "                        total_repositories_with_contributed_commits_before_spam_label += (\n",
    "                            total_repositories_with_contributed_commits\n",
    "                        )\n",
    "                        total_repositories_with_contributed_issues_before_spam_label += (\n",
    "                            total_repositories_with_contributed_issues\n",
    "                        )\n",
    "                        total_repositories_with_contributed_pull_request_reviews_before_spam_label += (\n",
    "                            total_repositories_with_contributed_pull_request_reviews\n",
    "                        )\n",
    "                        total_repositories_with_contributed_pull_requests_before_spam_label += (\n",
    "                            total_repositories_with_contributed_pull_requests\n",
    "                        )\n",
    "                        total_repository_contributions_before_spam_label += (\n",
    "                            total_repository_contributions\n",
    "                        )\n",
    "                        restricted_contributions_count_before_spam_label += (\n",
    "                            restricted_contributions_count\n",
    "                        )\n",
    "                    else:\n",
    "                        total_contributions_count_after_spam_label += contributions_count\n",
    "                        total_commit_contributions_after_spam_label += (\n",
    "                            total_commit_contributions\n",
    "                        )\n",
    "                        total_issue_contributions_after_spam_label += (\n",
    "                            total_issue_contributions\n",
    "                        )\n",
    "                        total_pull_request_contributions_after_spam_label += (\n",
    "                            total_pull_request_contributions\n",
    "                        )\n",
    "                        total_pull_request_review_contributions_after_spam_label += (\n",
    "                            total_pull_request_review_contributions\n",
    "                        )\n",
    "                        total_repositories_with_contributed_commits_after_spam_label += (\n",
    "                            total_repositories_with_contributed_commits\n",
    "                        )\n",
    "                        total_repositories_with_contributed_issues_after_spam_label += (\n",
    "                            total_repositories_with_contributed_issues\n",
    "                        )\n",
    "                        total_repositories_with_contributed_pull_request_reviews_after_spam_label += (\n",
    "                            total_repositories_with_contributed_pull_request_reviews\n",
    "                        )\n",
    "                        total_repositories_with_contributed_pull_requests_after_spam_label += (\n",
    "                            total_repositories_with_contributed_pull_requests\n",
    "                        )\n",
    "                        total_repository_contributions_after_spam_label += (\n",
    "                            total_repository_contributions\n",
    "                        )\n",
    "                        restricted_contributions_count_after_spam_label += (\n",
    "                            restricted_contributions_count\n",
    "                        )\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Save usercontrib-progress before terminating\n",
    "                    with open(\"user_contribution_count_progress.pkl\", \"wb\") as f:\n",
    "                        pickle.dump({\"df\": df, \"start_index\": index}, f)\n",
    "                    log_activity(f\"Error querying contributions for {username}: {e}\")\n",
    "                    break\n",
    "\n",
    "                if (\n",
    "                    user_query_end_date >= pr_labeled_spam_at\n",
    "                    and user_query_end_date >= current_date\n",
    "                ):\n",
    "                    break\n",
    "\n",
    "                if user_query_end_date == pr_labeled_spam_at:\n",
    "                    is_contribution_before_spam_label = False\n",
    "                user_query_start_date = user_query_end_date + datetime.timedelta(seconds=1)\n",
    "            df.append(\n",
    "                {\n",
    "                    \"pr_id\": pr_id,\n",
    "                    \"username\": username,\n",
    "                    \"pr_labeled_spam_at\": get_serializable_date_str(pr_labeled_spam_at),\n",
    "                    \"url\": response[\"user\"][\"url\"],\n",
    "                    \"total_contributions_count_before_spam_label\": total_contributions_count_before_spam_label,\n",
    "                    \"total_commit_contributions_before_spam_label\": total_commit_contributions_before_spam_label,\n",
    "                    \"total_issue_contributions_before_spam_label\": total_issue_contributions_before_spam_label,\n",
    "                    \"total_pull_request_contributions_before_spam_label\": total_pull_request_contributions_before_spam_label,\n",
    "                    \"total_pull_request_review_contributions_before_spam_label\": total_pull_request_review_contributions_before_spam_label,\n",
    "                    \"total_repositories_with_contributed_commits_before_spam_label\": total_repositories_with_contributed_commits_before_spam_label,\n",
    "                    \"total_repositories_with_contributed_issues_before_spam_label\": total_repositories_with_contributed_issues_before_spam_label,\n",
    "                    \"total_repositories_with_contributed_pull_request_reviews_before_spam_label\": total_repositories_with_contributed_pull_request_reviews_before_spam_label,\n",
    "                    \"total_repositories_with_contributed_pull_requests_before_spam_label\": total_repositories_with_contributed_pull_requests_before_spam_label,\n",
    "                    \"total_repository_contributions_before_spam_label\": total_repository_contributions_before_spam_label,\n",
    "                    \"restricted_contributions_count_before_spam_label\": restricted_contributions_count_before_spam_label,\n",
    "                    \"total_contributions_count_after_spam_label\": total_contributions_count_after_spam_label,\n",
    "                    \"total_commit_contributions_after_spam_label\": total_commit_contributions_after_spam_label,\n",
    "                    \"total_issue_contributions_after_spam_label\": total_issue_contributions_after_spam_label,\n",
    "                    \"total_pull_request_contributions_after_spam_label\": total_pull_request_contributions_after_spam_label,\n",
    "                    \"total_pull_request_review_contributions_after_spam_label\": total_pull_request_review_contributions_after_spam_label,\n",
    "                    \"total_repositories_with_contributed_commits_after_spam_label\": total_repositories_with_contributed_commits_after_spam_label,\n",
    "                    \"total_repositories_with_contributed_issues_after_spam_label\": total_repositories_with_contributed_issues_after_spam_label,\n",
    "                    \"total_repositories_with_contributed_pull_request_reviews_after_spam_label\": total_repositories_with_contributed_pull_request_reviews_after_spam_label,\n",
    "                    \"total_repositories_with_contributed_pull_requests_after_spam_label\": total_repositories_with_contributed_pull_requests_after_spam_label,\n",
    "                    \"total_repository_contributions_after_spam_label\": total_repository_contributions_after_spam_label,\n",
    "                    \"restricted_contributions_count_after_spam_label\": restricted_contributions_count_after_spam_label,\n",
    "                }\n",
    "            )\n",
    "            # Extract contributions\n",
    "            with open(\"seg_user_contribution_count_progress.pkl\", \"wb\") as f:\n",
    "                pickle.dump({\"df\": user_contribution_data, \"start_index\": index + 1}, f)\n",
    "        except Exception as e:\n",
    "            log_activity(\n",
    "                f\"Error fetching data for pr '{pr.get(\"id\")}': {e}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_pkl_content(filepath):\n",
    "    \"\"\"\n",
    "    Display the content of a pickle file and save it as CSV and JSON.\n",
    "    This function reads a pickle file from the given filepath, extracts the data,\n",
    "    and saves it as both a CSV and a JSON file. The CSV file is saved with the\n",
    "    filename 'seg_user_contribution_count.csv' and the JSON file is saved with the\n",
    "    filename 'seg_user_contribution_count.json'.\n",
    "    Parameters:\n",
    "    filepath (str): The path to the pickle file.\n",
    "    Raises:\n",
    "    Exception: If an error occurs while reading the pickle file or writing the CSV/JSON files.\n",
    "    Example:\n",
    "    display_pkl_content('/path/to/your/file.pkl')\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        log_activity(f\"Content of {filepath}:\\n\")\n",
    "        filename = \"seg_user_contribution_count\"\n",
    "        pd.DataFrame(data[\"df\"]).to_csv(f\"{filename}.csv\", index=True)\n",
    "        log_activity(f\"Data written to {filename}.csv successfully.\")\n",
    "        try:\n",
    "            with open(f\"{filename}.json\", \"w\") as f:\n",
    "                json.dump(data[\"df\"], f, indent=4)\n",
    "            log_activity(f\"Data written to {filename}.json successfully.\")\n",
    "        except Exception as e:\n",
    "            log_activity(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        log_activity(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "filepath = \"seg_user_contribution_count_progress.pkl\"  # Replace with the actual path to your .pkl file\n",
    "display_pkl_content(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469812ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
