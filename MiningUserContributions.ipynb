{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4babdda8-11f7-485e-bad8-d8c5b8eebb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "from datetime import datetime\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Read tokens from a text file\n",
    "tokens_file = \"./env/tokens.txt\"\n",
    "with open(tokens_file, \"r\") as file:\n",
    "    tokens = file.read().splitlines()\n",
    "\n",
    "# Create an iterator to cycle through the tokens\n",
    "token_iterator = itertools.cycle(tokens)\n",
    "current_token = next(token_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0c281d1-993b-497b-8984-0e32ac6a61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of User-Agents for randomization\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "]\n",
    "\n",
    "# Define headers to authenticate using the first token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {current_token}\",\n",
    "    \"User-Agent\": random.choice(user_agents),\n",
    "}\n",
    "\n",
    "# Setup GraphQL endpoint and client\n",
    "graphql_url = \"https://api.github.com/graphql\"\n",
    "transport = RequestsHTTPTransport(url=graphql_url, headers=headers, use_json=True)\n",
    "client = Client(transport=transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062f1b0-a9df-4f94-bb18-56f42774bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all tokens to verify their validity\n",
    "def test_all_tokens():\n",
    "    test_query = gql(\n",
    "        \"\"\"\n",
    "        {\n",
    "          viewer {\n",
    "            login\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "    )\n",
    "    for i, token in enumerate(tokens):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"User-Agent\": random.choice(user_agents),\n",
    "        }\n",
    "        transport = RequestsHTTPTransport(\n",
    "            url=graphql_url, headers=headers, use_json=True\n",
    "        )\n",
    "        client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "\n",
    "        try:\n",
    "            response = client.execute(test_query)\n",
    "            print(\n",
    "                f\"Token {i+1}/{len(tokens)} is valid. Logged in as: {response['viewer']['login']}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Token {i+1}/{len(tokens)} failed with error: {e}\")\n",
    "\n",
    "\n",
    "# Run the token validation\n",
    "test_all_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdd85df0-71b7-46c8-9ed4-eceb724201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphQL query\n",
    "query_template = gql(\n",
    "    \"\"\"\n",
    "      query($username: String!, $start: DateTime!, $end: DateTime!) {\n",
    "        user(login: $username) {\n",
    "          url\n",
    "          contributionsCollection(from: $start, to: $end) {\n",
    "            contributionCalendar {\n",
    "              totalContributions\n",
    "            }\n",
    "            totalCommitContributions\n",
    "            totalIssueContributions\n",
    "            totalPullRequestContributions\n",
    "            totalPullRequestReviewContributions\n",
    "            totalRepositoriesWithContributedCommits\n",
    "            totalRepositoriesWithContributedIssues\n",
    "            totalRepositoriesWithContributedPullRequestReviews\n",
    "            totalRepositoriesWithContributedPullRequests\n",
    "            totalRepositoryContributions\n",
    "            restrictedContributionsCount\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c2427-7797-4088-a144-6045c87ee349",
   "metadata": {},
   "outputs": [],
   "source": [
    "transport.headers = headers\n",
    "# Check rate limit before executing the main query\n",
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "rate_limit_response = client.execute(rate_limit_query)\n",
    "print(f\"Rate limit: {rate_limit_response['rateLimit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49acb9fd-7a25-458d-aec7-8f302a653c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limit_query = gql(\n",
    "    \"\"\"\n",
    "    query {\n",
    "      viewer {\n",
    "        login\n",
    "      }\n",
    "      rateLimit {\n",
    "        limit\n",
    "        remaining\n",
    "        used\n",
    "        resetAt\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def execute_query(username, start=100, end=None):\n",
    "    global current_token\n",
    "    print(\n",
    "        f\"Executing query with username: {username}, start: {start}, afterCursor: {end}\"\n",
    "    )\n",
    "    while True:\n",
    "        try:\n",
    "            # Randomize User-Agent for each query\n",
    "            headers[\"User-Agent\"] = random.choice(user_agents)\n",
    "            transport.headers = headers\n",
    "            # Check rate limit before executing the main query\n",
    "            rate_limit_response = client.execute(rate_limit_query)\n",
    "            remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "            if remaining < 100:\n",
    "                print(\n",
    "                    f\"Rate limit remaining ({remaining}) is below threshold. Switching token...\"\n",
    "                )\n",
    "                # Set up to track whether we have cycled through all tokens\n",
    "                all_tokens_checked = False\n",
    "                initial_token = current_token\n",
    "\n",
    "                while not all_tokens_checked:\n",
    "                    # Switch to the next token\n",
    "                    current_token = next(token_iterator)\n",
    "                    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "                    transport.headers = headers\n",
    "\n",
    "                    # Check the rate limit of the new token\n",
    "                    rate_limit_response = client.execute(rate_limit_query)\n",
    "                    remaining = rate_limit_response[\"rateLimit\"][\"remaining\"]\n",
    "\n",
    "                    if remaining >= 100:\n",
    "                        print(\n",
    "                            f\"Switched to a new token with sufficient rate limit ({remaining} remaining).\"\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    # Check if we have cycled through all tokens\n",
    "                    if current_token == initial_token:\n",
    "                        print(\"All tokens are below threshold. Waiting for 1 hour...\")\n",
    "                        time.sleep(3600)\n",
    "                        all_tokens_checked = True\n",
    "\n",
    "                continue\n",
    "            return client.execute(\n",
    "                query_template,\n",
    "                variable_values={\n",
    "                    \"username\": username,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                },\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if \"API rate limit\" in str(e):\n",
    "                print(\n",
    "                    f\"Rate limit reached: {e}, switching token... (Attempt with start {start} and end {end})\"\n",
    "                )\n",
    "                current_token = next(token_iterator)\n",
    "                headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "            else:\n",
    "                print(f\"Error: {e}, stopped during (Attempt with start {start} and end {end})\")\n",
    "                break\n",
    "                # if first > 1:\n",
    "                #     first = max(1, first // 2)\n",
    "                #     print(\n",
    "                #         f\"Error: {e}, reducing number of results and retrying... (Attempt with first {first})\"\n",
    "                #     )\n",
    "                # else:\n",
    "                #     break\n",
    "    print(\"Max retries reached. Sleeping for 60 minutes and switching token...\")\n",
    "    time.sleep(3600)\n",
    "    current_token = next(token_iterator)\n",
    "    headers[\"Authorization\"] = f\"Bearer {current_token}\"\n",
    "    transport.headers = headers\n",
    "    return execute_query(username, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10e2f9a0-95df-4b00-8544-efeb1ba4d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if os.path.exists(\"seg_user_contribution_count_progress.pkl\"):\n",
    "    with open(\"seg_user_contribution_count_progress.pkl\", \"rb\") as f:\n",
    "        progress_data = pickle.load(f)\n",
    "        df = progress_data[\"df\"]\n",
    "        start_index = progress_data[\"start_index\"]\n",
    "else:\n",
    "    df = []\n",
    "    start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb9c5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_datetime_str(date: str):\n",
    "    return datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def get_serializable_date_str(date: datetime.datetime):\n",
    "    try:\n",
    "        return date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e},\\n date:{date}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abb89147-ab2c-4654-a8d7-637737c90537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with username: luisAzcuaga, start: 2018-03-22T01:25:11Z, afterCursor: 2019-03-22T01:25:11Z\n",
      "Executing query with username: luisAzcuaga, start: 2019-03-22T01:25:12Z, afterCursor: 2020-03-21T01:25:12Z\n",
      "Executing query with username: luisAzcuaga, start: 2020-03-21T01:25:13Z, afterCursor: 2021-03-21T01:25:13Z\n",
      "Executing query with username: luisAzcuaga, start: 2021-03-21T01:25:14Z, afterCursor: 2021-10-27T08:29:55Z\n",
      "Executing query with username: luisAzcuaga, start: 2021-10-27T08:29:56Z, afterCursor: 2022-10-27T08:29:56Z\n",
      "Executing query with username: luisAzcuaga, start: 2022-10-27T08:29:57Z, afterCursor: 2023-10-27T08:29:57Z\n",
      "Executing query with username: luisAzcuaga, start: 2023-10-27T08:29:58Z, afterCursor: 2024-10-26T08:29:58Z\n",
      "Executing query with username: luisAzcuaga, start: 2024-10-26T08:29:59Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2018-08-11T15:08:57Z, afterCursor: 2019-08-11T15:08:57Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2019-08-11T15:08:58Z, afterCursor: 2020-08-10T15:08:58Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2020-08-10T15:08:59Z, afterCursor: 2021-08-10T15:08:59Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2021-08-10T15:09:00Z, afterCursor: 2021-10-18T06:36:16Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2021-10-18T06:36:17Z, afterCursor: 2022-10-18T06:36:17Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2022-10-18T06:36:18Z, afterCursor: 2023-10-18T06:36:18Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2023-10-18T06:36:19Z, afterCursor: 2024-10-17T06:36:19Z\n",
      "Executing query with username: EbhomenyeEmmanuel, start: 2024-10-17T06:36:20Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: mahmoudelsaka, start: 2017-04-02T13:36:14Z, afterCursor: 2018-04-02T13:36:14Z\n",
      "Executing query with username: mahmoudelsaka, start: 2018-04-02T13:36:15Z, afterCursor: 2019-04-02T13:36:15Z\n",
      "Executing query with username: mahmoudelsaka, start: 2019-04-02T13:36:16Z, afterCursor: 2020-04-01T13:36:16Z\n",
      "Executing query with username: mahmoudelsaka, start: 2020-04-01T13:36:17Z, afterCursor: 2021-04-01T13:36:17Z\n",
      "Executing query with username: mahmoudelsaka, start: 2021-04-01T13:36:18Z, afterCursor: 2021-10-11T09:56:19Z\n",
      "Executing query with username: mahmoudelsaka, start: 2021-10-11T09:56:20Z, afterCursor: 2022-10-11T09:56:20Z\n",
      "Executing query with username: mahmoudelsaka, start: 2022-10-11T09:56:21Z, afterCursor: 2023-10-11T09:56:21Z\n",
      "Executing query with username: mahmoudelsaka, start: 2023-10-11T09:56:22Z, afterCursor: 2024-10-10T09:56:22Z\n",
      "Executing query with username: mahmoudelsaka, start: 2024-10-10T09:56:23Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: mikidoodle, start: 2021-10-05T01:36:02Z, afterCursor: 2021-11-01T11:15:56Z\n",
      "Executing query with username: mikidoodle, start: 2021-11-01T11:15:57Z, afterCursor: 2022-11-01T11:15:57Z\n",
      "Executing query with username: mikidoodle, start: 2022-11-01T11:15:58Z, afterCursor: 2023-11-01T11:15:58Z\n",
      "Executing query with username: mikidoodle, start: 2023-11-01T11:15:59Z, afterCursor: 2024-10-31T11:15:59Z\n",
      "Executing query with username: mikidoodle, start: 2024-10-31T11:16:00Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: kartik-jobs, start: 2020-05-22T15:31:41Z, afterCursor: 2021-05-22T15:31:41Z\n",
      "Executing query with username: kartik-jobs, start: 2021-05-22T15:31:42Z, afterCursor: 2021-10-06T17:29:56Z\n",
      "Executing query with username: kartik-jobs, start: 2021-10-06T17:29:57Z, afterCursor: 2022-10-06T17:29:57Z\n",
      "Executing query with username: kartik-jobs, start: 2022-10-06T17:29:58Z, afterCursor: 2023-10-06T17:29:58Z\n",
      "Executing query with username: kartik-jobs, start: 2023-10-06T17:29:59Z, afterCursor: 2024-10-05T17:29:59Z\n",
      "Executing query with username: kartik-jobs, start: 2024-10-05T17:30:00Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: kalvik09, start: 2018-11-28T10:28:36Z, afterCursor: 2019-11-28T10:28:36Z\n",
      "Executing query with username: kalvik09, start: 2019-11-28T10:28:37Z, afterCursor: 2020-11-27T10:28:37Z\n",
      "Executing query with username: kalvik09, start: 2020-11-27T10:28:38Z, afterCursor: 2021-10-05T08:47:44Z\n",
      "Executing query with username: kalvik09, start: 2021-10-05T08:47:45Z, afterCursor: 2022-10-05T08:47:45Z\n",
      "Executing query with username: kalvik09, start: 2022-10-05T08:47:46Z, afterCursor: 2023-10-05T08:47:46Z\n",
      "Executing query with username: kalvik09, start: 2023-10-05T08:47:47Z, afterCursor: 2024-10-04T08:47:47Z\n",
      "Executing query with username: kalvik09, start: 2024-10-04T08:47:48Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: joshiayush, start: 2020-08-28T06:49:08Z, afterCursor: 2021-08-28T06:49:08Z\n",
      "Executing query with username: joshiayush, start: 2021-08-28T06:49:09Z, afterCursor: 2021-09-15T06:34:44Z\n",
      "Executing query with username: joshiayush, start: 2021-09-15T06:34:45Z, afterCursor: 2022-09-15T06:34:45Z\n",
      "Executing query with username: joshiayush, start: 2022-09-15T06:34:46Z, afterCursor: 2023-09-15T06:34:46Z\n",
      "Executing query with username: joshiayush, start: 2023-09-15T06:34:47Z, afterCursor: 2024-09-14T06:34:47Z\n",
      "Executing query with username: joshiayush, start: 2024-09-14T06:34:48Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: classicvalues, start: 2020-09-22T02:28:19Z, afterCursor: 2021-07-18T07:18:20Z\n",
      "Executing query with username: classicvalues, start: 2021-07-18T07:18:21Z, afterCursor: 2022-07-18T07:18:21Z\n",
      "Executing query with username: classicvalues, start: 2022-07-18T07:18:22Z, afterCursor: 2023-07-18T07:18:22Z\n",
      "Executing query with username: classicvalues, start: 2023-07-18T07:18:23Z, afterCursor: 2024-07-17T07:18:23Z\n",
      "Executing query with username: classicvalues, start: 2024-07-17T07:18:24Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: CanoBot, start: 2020-12-30T14:13:27Z, afterCursor: 2021-07-07T01:12:12Z\n",
      "Executing query with username: CanoBot, start: 2021-07-07T01:12:13Z, afterCursor: 2022-07-07T01:12:13Z\n",
      "Executing query with username: CanoBot, start: 2022-07-07T01:12:14Z, afterCursor: 2023-07-07T01:12:14Z\n",
      "Executing query with username: CanoBot, start: 2023-07-07T01:12:15Z, afterCursor: 2024-07-06T01:12:15Z\n",
      "Executing query with username: CanoBot, start: 2024-07-06T01:12:16Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: Karanragu, start: 2021-06-25T21:52:25Z, afterCursor: 2021-07-02T12:40:37Z\n",
      "Executing query with username: Karanragu, start: 2021-07-02T12:40:38Z, afterCursor: 2022-07-02T12:40:38Z\n",
      "Executing query with username: Karanragu, start: 2022-07-02T12:40:39Z, afterCursor: 2023-07-02T12:40:39Z\n",
      "Executing query with username: Karanragu, start: 2023-07-02T12:40:40Z, afterCursor: 2024-07-01T12:40:40Z\n",
      "Executing query with username: Karanragu, start: 2024-07-01T12:40:41Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: fiduchi, start: 2019-06-29T18:32:37Z, afterCursor: 2020-06-28T18:32:37Z\n",
      "Executing query with username: fiduchi, start: 2020-06-28T18:32:38Z, afterCursor: 2021-06-12T09:28:26Z\n",
      "Executing query with username: fiduchi, start: 2021-06-12T09:28:27Z, afterCursor: 2022-06-12T09:28:27Z\n",
      "Executing query with username: fiduchi, start: 2022-06-12T09:28:28Z, afterCursor: 2023-06-12T09:28:28Z\n",
      "Executing query with username: fiduchi, start: 2023-06-12T09:28:29Z, afterCursor: 2024-06-11T09:28:29Z\n",
      "Executing query with username: fiduchi, start: 2024-06-11T09:28:30Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: fiduchi, start: 2019-06-29T18:32:37Z, afterCursor: 2020-06-28T18:32:37Z\n",
      "Executing query with username: fiduchi, start: 2020-06-28T18:32:38Z, afterCursor: 2021-06-12T09:28:40Z\n",
      "Executing query with username: fiduchi, start: 2021-06-12T09:28:41Z, afterCursor: 2022-06-12T09:28:41Z\n",
      "Executing query with username: fiduchi, start: 2022-06-12T09:28:42Z, afterCursor: 2023-06-12T09:28:42Z\n",
      "Executing query with username: fiduchi, start: 2023-06-12T09:28:43Z, afterCursor: 2024-06-11T09:28:43Z\n",
      "Executing query with username: fiduchi, start: 2024-06-11T09:28:44Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: A-kriti, start: 2020-10-19T17:49:50Z, afterCursor: 2021-05-31T08:08:44Z\n",
      "Executing query with username: A-kriti, start: 2021-05-31T08:08:45Z, afterCursor: 2022-05-31T08:08:45Z\n",
      "Executing query with username: A-kriti, start: 2022-05-31T08:08:46Z, afterCursor: 2023-05-31T08:08:46Z\n",
      "Executing query with username: A-kriti, start: 2023-05-31T08:08:47Z, afterCursor: 2024-05-30T08:08:47Z\n",
      "Executing query with username: A-kriti, start: 2024-05-30T08:08:48Z, afterCursor: 2025-02-03T16:09:35Z\n",
      "Executing query with username: Dhanush2612, start: 2019-07-03T16:57:32Z, afterCursor: 2020-07-02T16:57:32Z\n",
      "Executing query with username: Dhanush2612, start: 2020-07-02T16:57:33Z, afterCursor: 2021-04-01T17:40:30Z\n",
      "Executing query with username: Dhanush2612, start: 2021-04-01T17:40:31Z, afterCursor: 2022-04-01T17:40:31Z\n",
      "Executing query with username: Dhanush2612, start: 2022-04-01T17:40:32Z, afterCursor: 2023-04-01T17:40:32Z\n",
      "Executing query with username: Dhanush2612, start: 2023-04-01T17:40:33Z, afterCursor: 2024-03-31T17:40:33Z\n",
      "Executing query with username: Dhanush2612, start: 2024-03-31T17:40:34Z, afterCursor: 2025-02-03T16:09:35Z\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "df = []\n",
    "start_index = 0\n",
    "\n",
    "index = start_index\n",
    "user_contribution_data = df\n",
    "current_date = datetime.datetime.now()\n",
    "all_contributions = {}\n",
    "with open(\"progress.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    spam_prs = data[\"df\"]\n",
    "    for pr in spam_prs:\n",
    "        pr_id = pr.get(\"id\")\n",
    "        username = pr.get(\"author_name\")\n",
    "\n",
    "        author_account_created_at = get_datetime_str(\n",
    "            pr.get(\"author_account_created_at\")\n",
    "        )\n",
    "        pr_created_at = get_datetime_str(pr.get(\"created_at\"))\n",
    "        pr_labeled_spam_at = get_datetime_str(pr.get(\"labeled_spam_at\"))\n",
    "\n",
    "        if not username or not pr_id:\n",
    "            continue\n",
    "\n",
    "        user_query_start_date = author_account_created_at\n",
    "        is_contribution_before_spam_label = True\n",
    "\n",
    "        # counts before spam label\n",
    "        total_contributions_count_before_spam_label = 0\n",
    "        total_commit_contributions_before_spam_label = 0\n",
    "        total_issue_contributions_before_spam_label = 0\n",
    "        total_pull_request_contributions_before_spam_label = 0\n",
    "        total_pull_request_review_contributions_before_spam_label = 0\n",
    "        total_repositories_with_contributed_commits_before_spam_label = 0\n",
    "        total_repositories_with_contributed_issues_before_spam_label = 0\n",
    "        total_repositories_with_contributed_pull_request_reviews_before_spam_label = 0\n",
    "        total_repositories_with_contributed_pull_requests_before_spam_label = 0\n",
    "        total_repository_contributions_before_spam_label = 0\n",
    "        restricted_contributions_count_before_spam_label = 0\n",
    "\n",
    "        # counts after spam label\n",
    "        total_contributions_count_after_spam_label = 0\n",
    "        total_commit_contributions_after_spam_label = 0\n",
    "        total_issue_contributions_after_spam_label = 0\n",
    "        total_pull_request_contributions_after_spam_label = 0\n",
    "        total_pull_request_review_contributions_after_spam_label = 0\n",
    "        total_repositories_with_contributed_commits_after_spam_label = 0\n",
    "        total_repositories_with_contributed_issues_after_spam_label = 0\n",
    "        total_repositories_with_contributed_pull_request_reviews_after_spam_label = 0\n",
    "        total_repositories_with_contributed_pull_requests_after_spam_label = 0\n",
    "        total_repository_contributions_after_spam_label = 0\n",
    "        restricted_contributions_count_after_spam_label = 0\n",
    "        while True:\n",
    "            one_year_from_start_date = user_query_start_date + datetime.timedelta(\n",
    "                days=365\n",
    "            )\n",
    "\n",
    "            if not is_contribution_before_spam_label:\n",
    "                user_query_end_date = min(one_year_from_start_date, current_date)\n",
    "            else:\n",
    "                user_query_end_date = min(one_year_from_start_date, pr_labeled_spam_at)\n",
    "\n",
    "            try:\n",
    "                response = execute_query(\n",
    "                    username,\n",
    "                    start=get_serializable_date_str(user_query_start_date),\n",
    "                    end=get_serializable_date_str(user_query_end_date),\n",
    "                )\n",
    "                contributionsCollection = response[\"user\"][\"contributionsCollection\"]\n",
    "\n",
    "                contributions_count = contributionsCollection[\"contributionCalendar\"][\n",
    "                    \"totalContributions\"\n",
    "                ]\n",
    "                total_commit_contributions = contributionsCollection[\n",
    "                    \"totalCommitContributions\"\n",
    "                ]\n",
    "                total_issue_contributions = contributionsCollection[\n",
    "                    \"totalIssueContributions\"\n",
    "                ]\n",
    "                total_pull_request_contributions = contributionsCollection[\n",
    "                    \"totalPullRequestContributions\"\n",
    "                ]\n",
    "                total_pull_request_review_contributions = contributionsCollection[\n",
    "                    \"totalPullRequestReviewContributions\"\n",
    "                ]\n",
    "                total_repositories_with_contributed_commits = contributionsCollection[\n",
    "                    \"totalRepositoriesWithContributedCommits\"\n",
    "                ]\n",
    "                total_repositories_with_contributed_issues = contributionsCollection[\n",
    "                    \"totalRepositoriesWithContributedIssues\"\n",
    "                ]\n",
    "                total_repositories_with_contributed_pull_request_reviews = (\n",
    "                    contributionsCollection[\n",
    "                        \"totalRepositoriesWithContributedPullRequestReviews\"\n",
    "                    ]\n",
    "                )\n",
    "                total_repositories_with_contributed_pull_requests = (\n",
    "                    contributionsCollection[\n",
    "                        \"totalRepositoriesWithContributedPullRequests\"\n",
    "                    ]\n",
    "                )\n",
    "                total_repository_contributions = contributionsCollection[\n",
    "                    \"totalRepositoryContributions\"\n",
    "                ]\n",
    "                restricted_contributions_count = contributionsCollection[\n",
    "                    \"restrictedContributionsCount\"\n",
    "                ]\n",
    "                if is_contribution_before_spam_label:\n",
    "                    total_contributions_count_before_spam_label += contributions_count\n",
    "                    total_commit_contributions_before_spam_label += (\n",
    "                        total_commit_contributions\n",
    "                    )\n",
    "                    total_issue_contributions_before_spam_label += (\n",
    "                        total_issue_contributions\n",
    "                    )\n",
    "                    total_pull_request_contributions_before_spam_label += (\n",
    "                        total_pull_request_contributions\n",
    "                    )\n",
    "                    total_pull_request_review_contributions_before_spam_label += (\n",
    "                        total_pull_request_review_contributions\n",
    "                    )\n",
    "                    total_repositories_with_contributed_commits_before_spam_label += (\n",
    "                        total_repositories_with_contributed_commits\n",
    "                    )\n",
    "                    total_repositories_with_contributed_issues_before_spam_label += (\n",
    "                        total_repositories_with_contributed_issues\n",
    "                    )\n",
    "                    total_repositories_with_contributed_pull_request_reviews_before_spam_label += (\n",
    "                        total_repositories_with_contributed_pull_request_reviews\n",
    "                    )\n",
    "                    total_repositories_with_contributed_pull_requests_before_spam_label += (\n",
    "                        total_repositories_with_contributed_pull_requests\n",
    "                    )\n",
    "                    total_repository_contributions_before_spam_label += (\n",
    "                        total_repository_contributions\n",
    "                    )\n",
    "                    restricted_contributions_count_before_spam_label += (\n",
    "                        restricted_contributions_count\n",
    "                    )\n",
    "                else:\n",
    "                    total_contributions_count_after_spam_label += contributions_count\n",
    "                    total_commit_contributions_after_spam_label += (\n",
    "                        total_commit_contributions\n",
    "                    )\n",
    "                    total_issue_contributions_after_spam_label += (\n",
    "                        total_issue_contributions\n",
    "                    )\n",
    "                    total_pull_request_contributions_after_spam_label += (\n",
    "                        total_pull_request_contributions\n",
    "                    )\n",
    "                    total_pull_request_review_contributions_after_spam_label += (\n",
    "                        total_pull_request_review_contributions\n",
    "                    )\n",
    "                    total_repositories_with_contributed_commits_after_spam_label += (\n",
    "                        total_repositories_with_contributed_commits\n",
    "                    )\n",
    "                    total_repositories_with_contributed_issues_after_spam_label += (\n",
    "                        total_repositories_with_contributed_issues\n",
    "                    )\n",
    "                    total_repositories_with_contributed_pull_request_reviews_after_spam_label += (\n",
    "                        total_repositories_with_contributed_pull_request_reviews\n",
    "                    )\n",
    "                    total_repositories_with_contributed_pull_requests_after_spam_label += (\n",
    "                        total_repositories_with_contributed_pull_requests\n",
    "                    )\n",
    "                    total_repository_contributions_after_spam_label += (\n",
    "                        total_repository_contributions\n",
    "                    )\n",
    "                    restricted_contributions_count_after_spam_label += (\n",
    "                        restricted_contributions_count\n",
    "                    )\n",
    "\n",
    "            except Exception as e:\n",
    "                # Save usercontrib-progress before terminating\n",
    "                with open(\"user_contribution_count_progress.pkl\", \"wb\") as f:\n",
    "                    pickle.dump({\"df\": df, \"start_index\": index}, f)\n",
    "                print(f\"Error querying contributions for {username}: {e}\")\n",
    "                break\n",
    "\n",
    "            if (\n",
    "                user_query_end_date >= pr_labeled_spam_at\n",
    "                and user_query_end_date >= current_date\n",
    "            ):\n",
    "                break\n",
    "\n",
    "            if user_query_end_date == pr_labeled_spam_at:\n",
    "                is_contribution_before_spam_label = False\n",
    "            user_query_start_date = user_query_end_date + datetime.timedelta(seconds=1)\n",
    "        df.append(\n",
    "            {\n",
    "                \"username\": username,\n",
    "                \"user_query_start_date\": get_serializable_date_str(\n",
    "                    user_query_start_date\n",
    "                ),\n",
    "                \"user_query_end_date\": get_serializable_date_str(\n",
    "                    user_query_end_date\n",
    "                ),\n",
    "                \"pr_labeled_spam_at\": get_serializable_date_str(pr_labeled_spam_at),\n",
    "                \"is_contribution_before_spam_label\": is_contribution_before_spam_label,\n",
    "                \"url\": response[\"user\"][\"url\"],\n",
    "                \"total_contributions_count_before_spam_label\": total_contributions_count_before_spam_label\n",
    "                ,\n",
    "                \"total_commit_contributions_before_spam_label\": total_commit_contributions_before_spam_label,\n",
    "                \"total_issue_contributions_before_spam_label\": total_issue_contributions_before_spam_label,\n",
    "                \"total_pull_request_contributions_before_spam_label\": total_pull_request_contributions_before_spam_label,\n",
    "                \"total_pull_request_review_contributions_before_spam_label\": total_pull_request_review_contributions_before_spam_label,\n",
    "                \"total_repositories_with_contributed_commits_before_spam_label\": total_repositories_with_contributed_commits_before_spam_label,\n",
    "                \"total_repositories_with_contributed_issues_before_spam_label\": total_repositories_with_contributed_issues_before_spam_label,\n",
    "                \"total_repositories_with_contributed_pull_request_reviews_before_spam_label\": total_repositories_with_contributed_pull_request_reviews_before_spam_label,\n",
    "                \"total_repositories_with_contributed_pull_requests_before_spam_label\": total_repositories_with_contributed_pull_requests_before_spam_label,\n",
    "                \"total_repository_contributions_before_spam_label\": total_repository_contributions_before_spam_label,\n",
    "                \"restricted_contributions_count_before_spam_label\": restricted_contributions_count_before_spam_label,\n",
    "                \"total_contributions_count_after_spam_label\": total_contributions_count_after_spam_label,\n",
    "                \"total_commit_contributions_after_spam_label\": total_commit_contributions_after_spam_label,\n",
    "                \"total_issue_contributions_after_spam_label\": total_issue_contributions_after_spam_label,\n",
    "                \"total_pull_request_contributions_after_spam_label\": total_pull_request_contributions_after_spam_label,\n",
    "                \"total_pull_request_review_contributions_after_spam_label\": total_pull_request_review_contributions_after_spam_label,\n",
    "                \"total_repositories_with_contributed_commits_after_spam_label\": total_repositories_with_contributed_commits_after_spam_label,\n",
    "                \"total_repositories_with_contributed_issues_after_spam_label\": total_repositories_with_contributed_issues_after_spam_label,\n",
    "                \"total_repositories_with_contributed_pull_request_reviews_after_spam_label\": total_repositories_with_contributed_pull_request_reviews_after_spam_label,\n",
    "                \"total_repositories_with_contributed_pull_requests_after_spam_label\": total_repositories_with_contributed_pull_requests_after_spam_label,\n",
    "                \"total_repository_contributions_after_spam_label\": total_repository_contributions_after_spam_label,\n",
    "                \"restricted_contributions_count_after_spam_label\": restricted_contributions_count_after_spam_label\n",
    "            }\n",
    "        )\n",
    "        # Extract contributions\n",
    "        with open(\"seg_user_contribution_count_progress.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\"df\": user_contribution_data, \"start_index\": index + 1}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24bca9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of seg_user_contribution_count_progress.pkl:\n",
      "\n",
      "Data written to seg_user_contribution_count.csv successfully.\n",
      "Data written to seg_user_contribution_count.json successfully.\n"
     ]
    }
   ],
   "source": [
    "from fileinput import filename\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_pkl_content(filepath):\n",
    "    \"\"\"\n",
    "    Display the content of a pickle file and save it as CSV and JSON.\n",
    "    This function reads a pickle file from the given filepath, extracts the data,\n",
    "    and saves it as both a CSV and a JSON file. The CSV file is saved with the\n",
    "    filename 'seg_user_contribution_count.csv' and the JSON file is saved with the\n",
    "    filename 'seg_user_contribution_count.json'.\n",
    "    Parameters:\n",
    "    filepath (str): The path to the pickle file.\n",
    "    Raises:\n",
    "    Exception: If an error occurs while reading the pickle file or writing the CSV/JSON files.\n",
    "    Example:\n",
    "    display_pkl_content('/path/to/your/file.pkl')\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        print(f\"Content of {filepath}:\\n\")\n",
    "        filename = \"seg_user_contribution_count\"\n",
    "        pd.DataFrame(data[\"df\"]).to_csv(f\"{filename}.csv\", index=True)\n",
    "        print(f\"Data written to {filename}.csv successfully.\")\n",
    "        try:\n",
    "            with open(f\"{filename}.json\", \"w\") as f:\n",
    "                json.dump(data[\"df\"], f, indent=4)\n",
    "            print(f\"Data written to {filename}.json successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "filepath = \"seg_user_contribution_count_progress.pkl\"  # Replace with the actual path to your .pkl file\n",
    "display_pkl_content(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469812ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
